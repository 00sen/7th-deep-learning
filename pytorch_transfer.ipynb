{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "## Luis Arturo\n",
    "### A01703572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexión a GPU local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ Successfully performed computation on GPU!\n",
      "Matrix multiplication result shape: torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test a simple GPU operation if available\n",
    "if device.type == \"cuda\":\n",
    "    try:\n",
    "        # Create some random data on the GPU\n",
    "        a = torch.randn(1000, 1000, device=device)\n",
    "        b = torch.randn(1000, 1000, device=device)\n",
    "        c = torch.matmul(a, b)  # Perform matrix multiplication\n",
    "        print(\"✅ Successfully performed computation on GPU!\")\n",
    "        print(f\"Matrix multiplication result shape: {c.shape}\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error during GPU computation:\", e)\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARGANDO DATASETS ===\n",
      "=== DATASETS CARGADOS ===\n"
     ]
    }
   ],
   "source": [
    "# 1. EXTRACT - Carga de datos\n",
    "print(\"=== CARGANDO DATASETS ===\")\n",
    "games_df = pd.read_csv('data/games.csv')\n",
    "users_df = pd.read_csv('data/users.csv')\n",
    "recommendations_df = pd.read_csv('data/recommendations.csv')\n",
    "\n",
    "print(\"=== DATASETS CARGADOS ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del games_df: (50872, 13)\n",
      "\n",
      "Columnas disponibles del games_df:\n",
      "- app_id\n",
      "- title\n",
      "- date_release\n",
      "- win\n",
      "- mac\n",
      "- linux\n",
      "- rating\n",
      "- positive_ratio\n",
      "- user_reviews\n",
      "- price_final\n",
      "- price_original\n",
      "- discount\n",
      "- steam_deck\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensiones del games_df:\", games_df.shape)\n",
    "print(\"\\nColumnas disponibles del games_df:\")\n",
    "for col in games_df.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del users_df: (14306064, 3)\n",
      "\n",
      "Columnas disponibles del users_df:\n",
      "- user_id\n",
      "- products\n",
      "- reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensiones del users_df:\", users_df.shape)\n",
    "print(\"\\nColumnas disponibles del users_df:\")\n",
    "for col in users_df.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del recommendations_df: (41154794, 8)\n",
      "\n",
      "Columnas disponibles del recommendations_df:\n",
      "- app_id\n",
      "- helpful\n",
      "- funny\n",
      "- date\n",
      "- is_recommended\n",
      "- hours\n",
      "- user_id\n",
      "- review_id\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensiones del recommendations_df:\", recommendations_df.shape)\n",
    "print(\"\\nColumnas disponibles del recommendations_df:\")\n",
    "for col in recommendations_df.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis inicial de games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 5 filas de games_df:\n",
      "   app_id                              title date_release   win    mac  linux  \\\n",
      "0   13500  Prince of Persia: Warrior Within™   2008-11-21  True  False  False   \n",
      "1   22364            BRINK: Agents of Change   2011-08-03  True  False  False   \n",
      "2  113020       Monaco: What's Yours Is Mine   2013-04-24  True   True   True   \n",
      "3  226560                 Escape Dead Island   2014-11-18  True  False  False   \n",
      "4  249050            Dungeon of the ENDLESS™   2014-10-27  True   True  False   \n",
      "\n",
      "          rating  positive_ratio  user_reviews  price_final  price_original  \\\n",
      "0  Very Positive              84          2199         9.99            9.99   \n",
      "1       Positive              85            21         2.99            2.99   \n",
      "2  Very Positive              92          3722        14.99           14.99   \n",
      "3          Mixed              61           873        14.99           14.99   \n",
      "4  Very Positive              88          8784        11.99           11.99   \n",
      "\n",
      "   discount  steam_deck  \n",
      "0       0.0        True  \n",
      "1       0.0        True  \n",
      "2       0.0        True  \n",
      "3       0.0        True  \n",
      "4       0.0        True  \n",
      "\n",
      "Información del dataset de juegos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50872 entries, 0 to 50871\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   app_id          50872 non-null  int64  \n",
      " 1   title           50872 non-null  object \n",
      " 2   date_release    50872 non-null  object \n",
      " 3   win             50872 non-null  bool   \n",
      " 4   mac             50872 non-null  bool   \n",
      " 5   linux           50872 non-null  bool   \n",
      " 6   rating          50872 non-null  object \n",
      " 7   positive_ratio  50872 non-null  int64  \n",
      " 8   user_reviews    50872 non-null  int64  \n",
      " 9   price_final     50872 non-null  float64\n",
      " 10  price_original  50872 non-null  float64\n",
      " 11  discount        50872 non-null  float64\n",
      " 12  steam_deck      50872 non-null  bool   \n",
      "dtypes: bool(4), float64(3), int64(3), object(3)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas de games_df:\n",
      "             app_id  positive_ratio  user_reviews   price_final  \\\n",
      "count  5.087200e+04    50872.000000  5.087200e+04  50872.000000   \n",
      "mean   1.055224e+06       77.052033  1.824425e+03      8.620325   \n",
      "std    6.103249e+05       18.253592  4.007352e+04     11.514164   \n",
      "min    1.000000e+01        0.000000  1.000000e+01      0.000000   \n",
      "25%    5.287375e+05       67.000000  1.900000e+01      0.990000   \n",
      "50%    9.860850e+05       81.000000  4.900000e+01      4.990000   \n",
      "75%    1.524895e+06       91.000000  2.060000e+02     10.990000   \n",
      "max    2.599300e+06      100.000000  7.494460e+06    299.990000   \n",
      "\n",
      "       price_original      discount  \n",
      "count    50872.000000  50872.000000  \n",
      "mean         8.726788      5.592212  \n",
      "std         11.507021     18.606679  \n",
      "min          0.000000      0.000000  \n",
      "25%          0.990000      0.000000  \n",
      "50%          4.990000      0.000000  \n",
      "75%         11.990000      0.000000  \n",
      "max        299.990000     90.000000  \n",
      "\n",
      "Valores nulos en games_df:\n",
      "app_id            0\n",
      "title             0\n",
      "date_release      0\n",
      "win               0\n",
      "mac               0\n",
      "linux             0\n",
      "rating            0\n",
      "positive_ratio    0\n",
      "user_reviews      0\n",
      "price_final       0\n",
      "price_original    0\n",
      "discount          0\n",
      "steam_deck        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrimeras 5 filas de games_df:\")\n",
    "print(games_df.head())\n",
    "print(\"\\nInformación del dataset de juegos:\")\n",
    "print(games_df.info())\n",
    "print(\"\\nEstadísticas descriptivas de games_df:\")\n",
    "print(games_df.describe())\n",
    "print(\"\\nValores nulos en games_df:\")\n",
    "print(games_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis inicial de users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 5 filas de users_df:\n",
      "    user_id  products  reviews\n",
      "0   7360263       359        0\n",
      "1  14020781       156        1\n",
      "2   8762579       329        4\n",
      "3   4820647       176        4\n",
      "4   5167327        98        2\n",
      "\n",
      "Información del dataset de usuarios:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14306064 entries, 0 to 14306063\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   products  int64\n",
      " 2   reviews   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 327.4 MB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas de users_df:\n",
      "            user_id      products       reviews\n",
      "count  1.430606e+07  1.430606e+07  1.430606e+07\n",
      "mean   7.153032e+06  1.163734e+02  2.876738e+00\n",
      "std    4.129805e+06  2.438515e+02  7.987421e+00\n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00\n",
      "25%    3.576516e+06  2.300000e+01  1.000000e+00\n",
      "50%    7.153032e+06  5.500000e+01  1.000000e+00\n",
      "75%    1.072955e+07  1.270000e+02  3.000000e+00\n",
      "max    1.430606e+07  3.221400e+04  6.045000e+03\n",
      "\n",
      "Valores nulos en users_df:\n",
      "user_id     0\n",
      "products    0\n",
      "reviews     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrimeras 5 filas de users_df:\")\n",
    "print(users_df.head())\n",
    "print(\"\\nInformación del dataset de usuarios:\")\n",
    "print(users_df.info())\n",
    "print(\"\\nEstadísticas descriptivas de users_df:\")\n",
    "print(users_df.describe())\n",
    "print(\"\\nValores nulos en users_df:\")\n",
    "print(users_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis inicial de recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 5 filas de recommendations_df:\n",
      "    app_id  helpful  funny        date  is_recommended  hours  user_id  \\\n",
      "0   975370        0      0  2022-12-12            True   36.3    51580   \n",
      "1   304390        4      0  2017-02-17           False   11.5     2586   \n",
      "2  1085660        2      0  2019-11-17            True  336.5   253880   \n",
      "3   703080        0      0  2022-09-23            True   27.4   259432   \n",
      "4   526870        0      0  2021-01-10            True    7.9    23869   \n",
      "\n",
      "   review_id  \n",
      "0          0  \n",
      "1          1  \n",
      "2          2  \n",
      "3          3  \n",
      "4          4  \n",
      "\n",
      "Información del dataset de recomendaciones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41154794 entries, 0 to 41154793\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   app_id          int64  \n",
      " 1   helpful         int64  \n",
      " 2   funny           int64  \n",
      " 3   date            object \n",
      " 4   is_recommended  bool   \n",
      " 5   hours           float64\n",
      " 6   user_id         int64  \n",
      " 7   review_id       int64  \n",
      "dtypes: bool(1), float64(1), int64(5), object(1)\n",
      "memory usage: 2.2+ GB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas de recommendations_df:\n",
      "             app_id       helpful         funny         hours       user_id  \\\n",
      "count  4.115479e+07  4.115479e+07  4.115479e+07  4.115479e+07  4.115479e+07   \n",
      "mean   6.032724e+05  3.202567e+00  1.058071e+00  1.006022e+02  7.450576e+06   \n",
      "std    4.729233e+05  4.693649e+01  2.867060e+01  1.761675e+02  4.010685e+06   \n",
      "min    1.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    2.539400e+05  0.000000e+00  0.000000e+00  7.800000e+00  4.287256e+06   \n",
      "50%    4.351500e+05  0.000000e+00  0.000000e+00  2.730000e+01  7.546446e+06   \n",
      "75%    9.331100e+05  0.000000e+00  0.000000e+00  9.920000e+01  1.096877e+07   \n",
      "max    2.253290e+06  3.621200e+04  2.810900e+04  1.000000e+03  1.430606e+07   \n",
      "\n",
      "          review_id  \n",
      "count  4.115479e+07  \n",
      "mean   2.057740e+07  \n",
      "std    1.188037e+07  \n",
      "min    0.000000e+00  \n",
      "25%    1.028870e+07  \n",
      "50%    2.057740e+07  \n",
      "75%    3.086609e+07  \n",
      "max    4.115479e+07  \n",
      "\n",
      "Valores nulos en recommendations_df:\n",
      "app_id            0\n",
      "helpful           0\n",
      "funny             0\n",
      "date              0\n",
      "is_recommended    0\n",
      "hours             0\n",
      "user_id           0\n",
      "review_id         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrimeras 5 filas de recommendations_df:\")\n",
    "print(recommendations_df.head())\n",
    "print(\"\\nInformación del dataset de recomendaciones:\")\n",
    "print(recommendations_df.info())\n",
    "print(\"\\nEstadísticas descriptivas de recommendations_df:\")\n",
    "print(recommendations_df.describe())\n",
    "print(\"\\nValores nulos en recommendations_df:\")\n",
    "print(recommendations_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis expecífico de features importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de ratings en juegos:\n",
      "rating\n",
      "Positive                   13502\n",
      "Very Positive              13139\n",
      "Mixed                      12157\n",
      "Mostly Positive             8738\n",
      "Mostly Negative             1849\n",
      "Overwhelmingly Positive     1110\n",
      "Negative                     303\n",
      "Very Negative                 60\n",
      "Overwhelmingly Negative       14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de ratings\n",
    "print(\"\\nDistribución de ratings en juegos:\")\n",
    "print(games_df['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de precios:\n",
      "        price_final  price_original\n",
      "count  50872.000000    50872.000000\n",
      "mean       8.620325        8.726788\n",
      "std       11.514164       11.507021\n",
      "min        0.000000        0.000000\n",
      "25%        0.990000        0.990000\n",
      "50%        4.990000        4.990000\n",
      "75%       10.990000       11.990000\n",
      "max      299.990000      299.990000\n"
     ]
    }
   ],
   "source": [
    "# Análisis de precios\n",
    "print(\"\\nEstadísticas de precios:\")\n",
    "print(games_df[['price_final', 'price_original']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de recomendaciones:\n",
      "is_recommended\n",
      "True     0.857844\n",
      "False    0.142156\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de recomendaciones\n",
    "print(\"\\nDistribución de recomendaciones:\")\n",
    "print(recommendations_df['is_recommended'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de horas jugadas:\n",
      "count    4.115479e+07\n",
      "mean     1.006022e+02\n",
      "std      1.761675e+02\n",
      "min      0.000000e+00\n",
      "25%      7.800000e+00\n",
      "50%      2.730000e+01\n",
      "75%      9.920000e+01\n",
      "max      1.000000e+03\n",
      "Name: hours, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de horas jugadas\n",
    "print(\"\\nEstadísticas de horas jugadas:\")\n",
    "print(recommendations_df['hours'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos la integridad de referencias entre los datasets\n",
    "Nos aseguramos de que los juegos y los usuarios referenciados en reseñas existen en el dataset de juegos y en el de usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Juegos en recommendations pero no en games: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar si todos los app_id en recommendations existen en games\n",
    "games_apps = set(games_df['app_id'])\n",
    "recommendations_apps = set(recommendations_df['app_id'])\n",
    "print(\"\\nJuegos en recommendations pero no en games:\", len(recommendations_apps - games_apps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios en recommendations pero no en users: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar si todos los user_id en recommendations existen en users\n",
    "users_ids = set(users_df['user_id'])\n",
    "recommendations_users = set(recommendations_df['user_id'])\n",
    "print(\"Usuarios en recommendations pero no en users:\", len(recommendations_users - users_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se va a crear un modelo capaz de predecir el rating que tendrá un juego (\"Very Positive\", \"Mixed\", etc.) \n",
    "## Son 9 clases \n",
    "- Positive                   13502\n",
    "- Very Positive              13139\n",
    "- Mixed                      12157\n",
    "- Mostly Positive             8738\n",
    "- Mostly Negative             1849\n",
    "- Overwhelmingly Positive     1110\n",
    "- Negative                     303\n",
    "- Very Negative                 60\n",
    "- Overwhelmingly Negative       14\n",
    "\n",
    "## Features de entrada\n",
    "- Precio\n",
    "- Plataformas soportadas (win, mac, linux)\n",
    "- Tiempo en el mercado\n",
    "- Descuentos\n",
    "- Métricas agregadas de reviews (horas promedio jugadas, ratio de recomendaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiendo de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos features en base a las recomendaciones de los juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_metrics = recommendations_df.groupby('app_id').agg({\n",
    "    'hours': ['mean', 'median', 'std'],\n",
    "    'is_recommended': 'mean',\n",
    "    'helpful': 'mean',\n",
    "    'funny': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Aplanar los nombres de las columnas\n",
    "game_metrics.columns = ['app_id', 'avg_hours', 'median_hours', 'std_hours', \n",
    "                        'recommendation_ratio', 'avg_helpful', 'avg_funny']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamos las fechas para calcular el tiempo que el juego ha estado en el mercado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['date_release'] = pd.to_datetime(games_df['date_release'])\n",
    "reference_date = pd.to_datetime('2024-11-01')  # Fecha de referencia\n",
    "games_df['days_in_market'] = (reference_date - games_df['date_release']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unimos los nuevos features en un dataset final usando como base el de games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = games_df.merge(game_metrics, on='app_id', how='left')\n",
    "    \n",
    "# 4. Rellenar valores nulos\n",
    "final_df = final_df.fillna({\n",
    "    'avg_hours': 0,\n",
    "    'median_hours': 0,\n",
    "    'std_hours': 0,\n",
    "    'recommendation_ratio': 0.5,\n",
    "    'avg_helpful': 0,\n",
    "    'avg_funny': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date_release</th>\n",
       "      <th>win</th>\n",
       "      <th>mac</th>\n",
       "      <th>linux</th>\n",
       "      <th>rating</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>price_final</th>\n",
       "      <th>price_original</th>\n",
       "      <th>discount</th>\n",
       "      <th>steam_deck</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>median_hours</th>\n",
       "      <th>std_hours</th>\n",
       "      <th>recommendation_ratio</th>\n",
       "      <th>avg_helpful</th>\n",
       "      <th>avg_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>Prince of Persia: Warrior Within™</td>\n",
       "      <td>2008-11-21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>84</td>\n",
       "      <td>2199</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5824</td>\n",
       "      <td>18.967912</td>\n",
       "      <td>12.9</td>\n",
       "      <td>41.722269</td>\n",
       "      <td>0.845789</td>\n",
       "      <td>5.392052</td>\n",
       "      <td>0.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22364</td>\n",
       "      <td>BRINK: Agents of Change</td>\n",
       "      <td>2011-08-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113020</td>\n",
       "      <td>Monaco: What's Yours Is Mine</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>92</td>\n",
       "      <td>3722</td>\n",
       "      <td>14.99</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4209</td>\n",
       "      <td>20.413294</td>\n",
       "      <td>6.9</td>\n",
       "      <td>53.295053</td>\n",
       "      <td>0.908541</td>\n",
       "      <td>1.434682</td>\n",
       "      <td>0.450382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226560</td>\n",
       "      <td>Escape Dead Island</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>61</td>\n",
       "      <td>873</td>\n",
       "      <td>14.99</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3636</td>\n",
       "      <td>10.776625</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15.421851</td>\n",
       "      <td>0.625998</td>\n",
       "      <td>6.778791</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249050</td>\n",
       "      <td>Dungeon of the ENDLESS™</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>88</td>\n",
       "      <td>8784</td>\n",
       "      <td>11.99</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3658</td>\n",
       "      <td>40.621691</td>\n",
       "      <td>23.4</td>\n",
       "      <td>54.860085</td>\n",
       "      <td>0.885567</td>\n",
       "      <td>2.530928</td>\n",
       "      <td>0.698351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id                              title date_release   win    mac  linux  \\\n",
       "0   13500  Prince of Persia: Warrior Within™   2008-11-21  True  False  False   \n",
       "1   22364            BRINK: Agents of Change   2011-08-03  True  False  False   \n",
       "2  113020       Monaco: What's Yours Is Mine   2013-04-24  True   True   True   \n",
       "3  226560                 Escape Dead Island   2014-11-18  True  False  False   \n",
       "4  249050            Dungeon of the ENDLESS™   2014-10-27  True   True  False   \n",
       "\n",
       "          rating  positive_ratio  user_reviews  price_final  price_original  \\\n",
       "0  Very Positive              84          2199         9.99            9.99   \n",
       "1       Positive              85            21         2.99            2.99   \n",
       "2  Very Positive              92          3722        14.99           14.99   \n",
       "3          Mixed              61           873        14.99           14.99   \n",
       "4  Very Positive              88          8784        11.99           11.99   \n",
       "\n",
       "   discount  steam_deck  days_in_market  avg_hours  median_hours  std_hours  \\\n",
       "0       0.0        True            5824  18.967912          12.9  41.722269   \n",
       "1       0.0        True            4839   0.000000           0.0   0.000000   \n",
       "2       0.0        True            4209  20.413294           6.9  53.295053   \n",
       "3       0.0        True            3636  10.776625           8.1  15.421851   \n",
       "4       0.0        True            3658  40.621691          23.4  54.860085   \n",
       "\n",
       "   recommendation_ratio  avg_helpful  avg_funny  \n",
       "0              0.845789     5.392052   0.612100  \n",
       "1              0.500000     0.000000   0.000000  \n",
       "2              0.908541     1.434682   0.450382  \n",
       "3              0.625998     6.778791   0.815279  \n",
       "4              0.885567     2.530928   0.698351  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>date_release</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>price_final</th>\n",
       "      <th>price_original</th>\n",
       "      <th>discount</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>median_hours</th>\n",
       "      <th>std_hours</th>\n",
       "      <th>recommendation_ratio</th>\n",
       "      <th>avg_helpful</th>\n",
       "      <th>avg_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.087200e+04</td>\n",
       "      <td>50872</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>5.087200e+04</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "      <td>50872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.055224e+06</td>\n",
       "      <td>2019-03-13 03:53:57.112753664</td>\n",
       "      <td>77.052033</td>\n",
       "      <td>1.824425e+03</td>\n",
       "      <td>8.620325</td>\n",
       "      <td>8.726788</td>\n",
       "      <td>5.592212</td>\n",
       "      <td>2059.837533</td>\n",
       "      <td>12.017546</td>\n",
       "      <td>5.630656</td>\n",
       "      <td>21.209406</td>\n",
       "      <td>0.697721</td>\n",
       "      <td>2.927259</td>\n",
       "      <td>0.496619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1997-06-30 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.287375e+05</td>\n",
       "      <td>2017-03-21 00:00:00</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.860850e+05</td>\n",
       "      <td>2019-08-23 00:00:00</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1897.000000</td>\n",
       "      <td>3.436826</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.186043</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.178243</td>\n",
       "      <td>0.131972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.524895e+06</td>\n",
       "      <td>2021-09-21 00:00:00</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>11.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2782.000000</td>\n",
       "      <td>10.730804</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.601544</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.482362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.599300e+06</td>\n",
       "      <td>2023-10-24 00:00:00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.494460e+06</td>\n",
       "      <td>299.990000</td>\n",
       "      <td>299.990000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>511.500000</td>\n",
       "      <td>495.120177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>268.285714</td>\n",
       "      <td>266.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.103249e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.253592</td>\n",
       "      <td>4.007352e+04</td>\n",
       "      <td>11.514164</td>\n",
       "      <td>11.507021</td>\n",
       "      <td>18.606679</td>\n",
       "      <td>1125.133076</td>\n",
       "      <td>28.005183</td>\n",
       "      <td>16.127001</td>\n",
       "      <td>41.136308</td>\n",
       "      <td>0.204218</td>\n",
       "      <td>4.689921</td>\n",
       "      <td>2.481174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             app_id                   date_release  positive_ratio  \\\n",
       "count  5.087200e+04                          50872    50872.000000   \n",
       "mean   1.055224e+06  2019-03-13 03:53:57.112753664       77.052033   \n",
       "min    1.000000e+01            1997-06-30 00:00:00        0.000000   \n",
       "25%    5.287375e+05            2017-03-21 00:00:00       67.000000   \n",
       "50%    9.860850e+05            2019-08-23 00:00:00       81.000000   \n",
       "75%    1.524895e+06            2021-09-21 00:00:00       91.000000   \n",
       "max    2.599300e+06            2023-10-24 00:00:00      100.000000   \n",
       "std    6.103249e+05                            NaN       18.253592   \n",
       "\n",
       "       user_reviews   price_final  price_original      discount  \\\n",
       "count  5.087200e+04  50872.000000    50872.000000  50872.000000   \n",
       "mean   1.824425e+03      8.620325        8.726788      5.592212   \n",
       "min    1.000000e+01      0.000000        0.000000      0.000000   \n",
       "25%    1.900000e+01      0.990000        0.990000      0.000000   \n",
       "50%    4.900000e+01      4.990000        4.990000      0.000000   \n",
       "75%    2.060000e+02     10.990000       11.990000      0.000000   \n",
       "max    7.494460e+06    299.990000      299.990000     90.000000   \n",
       "std    4.007352e+04     11.514164       11.507021     18.606679   \n",
       "\n",
       "       days_in_market     avg_hours  median_hours     std_hours  \\\n",
       "count    50872.000000  50872.000000  50872.000000  50872.000000   \n",
       "mean      2059.837533     12.017546      5.630656     21.209406   \n",
       "min        374.000000      0.000000      0.000000      0.000000   \n",
       "25%       1137.000000      0.000000      0.000000      0.000000   \n",
       "50%       1897.000000      3.436826      1.500000      4.186043   \n",
       "75%       2782.000000     10.730804      5.000000     21.601544   \n",
       "max       9986.000000    487.000000    511.500000    495.120177   \n",
       "std       1125.133076     28.005183     16.127001     41.136308   \n",
       "\n",
       "       recommendation_ratio   avg_helpful     avg_funny  \n",
       "count          50872.000000  50872.000000  50872.000000  \n",
       "mean               0.697721      2.927259      0.496619  \n",
       "min                0.000000      0.000000      0.000000  \n",
       "25%                0.500000      0.000000      0.000000  \n",
       "50%                0.714286      2.178243      0.131972  \n",
       "75%                0.881546      4.000000      0.482362  \n",
       "max                1.000000    268.285714    266.285714  \n",
       "std                0.204218      4.689921      2.481174  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id                              2599300\n",
       "title                      🧠 OUT OF THE BOX\n",
       "date_release            2023-10-24 00:00:00\n",
       "win                                    True\n",
       "mac                                    True\n",
       "linux                                  True\n",
       "rating                        Very Positive\n",
       "positive_ratio                          100\n",
       "user_reviews                        7494460\n",
       "price_final                          299.99\n",
       "price_original                       299.99\n",
       "discount                               90.0\n",
       "steam_deck                             True\n",
       "days_in_market                         9986\n",
       "avg_hours                             487.0\n",
       "median_hours                          511.5\n",
       "std_hours                        495.120177\n",
       "recommendation_ratio                    1.0\n",
       "avg_helpful                      268.285714\n",
       "avg_funny                        266.285714\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se encontró un juego que posee métricas exageradas, al compararlo con Steam nos dimos cuenta de que parece ser un error\n",
    "En base a esto imprimimos todos los juegos que tienen un precion final mayor a 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "juegos_filtrados = final_df[final_df['price_final'] > 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date_release</th>\n",
       "      <th>win</th>\n",
       "      <th>mac</th>\n",
       "      <th>linux</th>\n",
       "      <th>rating</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>price_final</th>\n",
       "      <th>price_original</th>\n",
       "      <th>discount</th>\n",
       "      <th>steam_deck</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>median_hours</th>\n",
       "      <th>std_hours</th>\n",
       "      <th>recommendation_ratio</th>\n",
       "      <th>avg_helpful</th>\n",
       "      <th>avg_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>438450</td>\n",
       "      <td>3DF Zephyr Lite Steam Edition</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>96</td>\n",
       "      <td>58</td>\n",
       "      <td>199.99</td>\n",
       "      <td>199.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3195</td>\n",
       "      <td>243.356250</td>\n",
       "      <td>121.35</td>\n",
       "      <td>265.982864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.979167</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>537770</td>\n",
       "      <td>Gal*Gun: Double Peace - 'Pheromone Z' Item</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "      <td>89.99</td>\n",
       "      <td>89.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>554820</td>\n",
       "      <td>VideoPad Video Editor</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2892</td>\n",
       "      <td>221.103030</td>\n",
       "      <td>130.70</td>\n",
       "      <td>238.796225</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>3.212121</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1076160</td>\n",
       "      <td>Command: Modern Operations</td>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>84</td>\n",
       "      <td>897</td>\n",
       "      <td>79.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1814</td>\n",
       "      <td>126.815050</td>\n",
       "      <td>49.00</td>\n",
       "      <td>186.176124</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>12.749164</td>\n",
       "      <td>5.050167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>1182920</td>\n",
       "      <td>Movavi Video Editor Plus 2020 - Video Editing ...</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>80</td>\n",
       "      <td>874</td>\n",
       "      <td>74.99</td>\n",
       "      <td>74.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1803</td>\n",
       "      <td>111.442762</td>\n",
       "      <td>56.80</td>\n",
       "      <td>161.577714</td>\n",
       "      <td>0.788419</td>\n",
       "      <td>1.817372</td>\n",
       "      <td>0.227171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47765</th>\n",
       "      <td>411893</td>\n",
       "      <td>DCS: F-14A/B Tomcat</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>92</td>\n",
       "      <td>555</td>\n",
       "      <td>79.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48354</th>\n",
       "      <td>1096900</td>\n",
       "      <td>RPG Maker MZ</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>83</td>\n",
       "      <td>1070</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1527</td>\n",
       "      <td>186.038028</td>\n",
       "      <td>72.85</td>\n",
       "      <td>249.288267</td>\n",
       "      <td>0.791080</td>\n",
       "      <td>16.969484</td>\n",
       "      <td>3.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49167</th>\n",
       "      <td>2199970</td>\n",
       "      <td>Substance 3D Painter 2023</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>85</td>\n",
       "      <td>148</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49310</th>\n",
       "      <td>2070990</td>\n",
       "      <td>VEGAS Edit 20 Steam Edition</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>66</td>\n",
       "      <td>21</td>\n",
       "      <td>129.48</td>\n",
       "      <td>249.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>True</td>\n",
       "      <td>731</td>\n",
       "      <td>68.566667</td>\n",
       "      <td>5.60</td>\n",
       "      <td>113.331475</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49880</th>\n",
       "      <td>931980</td>\n",
       "      <td>Dreadnought Outlaw Hoard DLC</td>\n",
       "      <td>2018-10-14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "      <td>87</td>\n",
       "      <td>16</td>\n",
       "      <td>79.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        app_id                                              title  \\\n",
       "81      438450                      3DF Zephyr Lite Steam Edition   \n",
       "144     537770         Gal*Gun: Double Peace - 'Pheromone Z' Item   \n",
       "190     554820                              VideoPad Video Editor   \n",
       "403    1076160                         Command: Modern Operations   \n",
       "675    1182920  Movavi Video Editor Plus 2020 - Video Editing ...   \n",
       "...        ...                                                ...   \n",
       "47765   411893                                DCS: F-14A/B Tomcat   \n",
       "48354  1096900                                       RPG Maker MZ   \n",
       "49167  2199970                          Substance 3D Painter 2023   \n",
       "49310  2070990                        VEGAS Edit 20 Steam Edition   \n",
       "49880   931980                       Dreadnought Outlaw Hoard DLC   \n",
       "\n",
       "      date_release   win    mac  linux         rating  positive_ratio  \\\n",
       "81      2016-02-02  True  False  False  Very Positive              96   \n",
       "144     2016-10-20  True  False  False       Positive              91   \n",
       "190     2016-12-01  True   True  False  Very Positive              80   \n",
       "403     2019-11-14  True  False  False  Very Positive              84   \n",
       "675     2019-11-25  True   True  False  Very Positive              80   \n",
       "...            ...   ...    ...    ...            ...             ...   \n",
       "47765   2019-03-13  True  False  False  Very Positive              92   \n",
       "48354   2020-08-27  True   True  False  Very Positive              83   \n",
       "49167   2023-01-23  True   True   True  Very Positive              85   \n",
       "49310   2022-11-01  True  False  False          Mixed              66   \n",
       "49880   2018-10-14  True  False  False       Positive              87   \n",
       "\n",
       "       user_reviews  price_final  price_original  discount  steam_deck  \\\n",
       "81               58       199.99          199.99       0.0        True   \n",
       "144              12        89.99           89.99       0.0        True   \n",
       "190              51        99.99           99.99       0.0        True   \n",
       "403             897        79.99           79.99       0.0        True   \n",
       "675             874        74.99           74.99       0.0        True   \n",
       "...             ...          ...             ...       ...         ...   \n",
       "47765           555        79.99           79.99       0.0        True   \n",
       "48354          1070        80.00            0.00       0.0        True   \n",
       "49167           148       150.00            0.00       0.0        True   \n",
       "49310            21       129.48          249.00      48.0        True   \n",
       "49880            16        79.99           79.99       0.0        True   \n",
       "\n",
       "       days_in_market   avg_hours  median_hours   std_hours  \\\n",
       "81               3195  243.356250        121.35  265.982864   \n",
       "144              2934    0.000000          0.00    0.000000   \n",
       "190              2892  221.103030        130.70  238.796225   \n",
       "403              1814  126.815050         49.00  186.176124   \n",
       "675              1803  111.442762         56.80  161.577714   \n",
       "...               ...         ...           ...         ...   \n",
       "47765            2060    0.000000          0.00    0.000000   \n",
       "48354            1527  186.038028         72.85  249.288267   \n",
       "49167             648    0.000000          0.00    0.000000   \n",
       "49310             731   68.566667          5.60  113.331475   \n",
       "49880            2210    0.000000          0.00    0.000000   \n",
       "\n",
       "       recommendation_ratio  avg_helpful  avg_funny  \n",
       "81                 1.000000     4.979167   0.750000  \n",
       "144                0.500000     0.000000   0.000000  \n",
       "190                0.787879     3.212121   0.242424  \n",
       "403                0.859532    12.749164   5.050167  \n",
       "675                0.788419     1.817372   0.227171  \n",
       "...                     ...          ...        ...  \n",
       "47765              0.500000     0.000000   0.000000  \n",
       "48354              0.791080    16.969484   3.521127  \n",
       "49167              0.500000     0.000000   0.000000  \n",
       "49310              0.666667    19.333333   5.333333  \n",
       "49880              0.500000     0.000000   0.000000  \n",
       "\n",
       "[150 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juegos_filtrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser solo 150 juegos, decidimos tirarlos para evitar conflictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['price_final'] <= 70].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['price_original'] <= 70].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id                              2599300\n",
       "title                      🧠 OUT OF THE BOX\n",
       "date_release            2023-10-24 00:00:00\n",
       "win                                    True\n",
       "mac                                    True\n",
       "linux                                  True\n",
       "rating                        Very Positive\n",
       "positive_ratio                          100\n",
       "user_reviews                        7494460\n",
       "price_final                            70.0\n",
       "price_original                        69.99\n",
       "discount                               90.0\n",
       "steam_deck                             True\n",
       "days_in_market                         9986\n",
       "avg_hours                             487.0\n",
       "median_hours                          511.5\n",
       "std_hours                        495.120177\n",
       "recommendation_ratio                    1.0\n",
       "avg_helpful                      268.285714\n",
       "avg_funny                        266.285714\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parece ser que hay juegos con nombres repetidos, eliminamos aquellos que esten repetidos ya que solo son 121 títulos problemáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de títulos duplicados: 121\n",
      "Títulos duplicados: ['Prison Wars' 'The Good Life' 'RUSH' 'Hide and Seek' 'Remnants'\n",
      " 'Blade of Darkness' 'The Cleaner' 'Rogue' 'Lighthouse Keeper' 'Valor'\n",
      " 'Last Stop' 'fishy' 'Flashback' 'The Hotel' '3D Organon Anatomy'\n",
      " 'Minotaur' 'Northern Lights' 'First Snow' 'Momentum' 'Alter Ego'\n",
      " 'The Backrooms' 'Locked Up' 'Get Stuffed!' 'Ascent' 'The Hunt' 'Hatch'\n",
      " 'Lost' 'Warhammer Quest' 'Apollo 11 VR' 'Psych' 'Eternal Return'\n",
      " 'Achievement Clicker' 'Call of Duty®' 'Causality' 'The Lost Village'\n",
      " 'Resonance' 'Dead Forest' 'Lost Marbles' 'Wanderer' 'Castles' 'Grapple'\n",
      " 'Chaos Theory' 'Dungeon Warriors' 'Bounce' 'Evolution' 'Zombie Survivors'\n",
      " 'Ritual' 'Archery Simulator' 'Outpost' 'Shutter' 'The Line' 'The Village'\n",
      " 'The Wanderer' 'Fantasy Gladiators' 'Cave Crawler' 'Cursed'\n",
      " 'A Walk in the Woods' 'Dark Matter' 'Beyond the Wall' 'White Mirror'\n",
      " 'Zombie Apocalypse' 'RIFT' 'STAY' 'Silent World' 'REALITY' 'Tomorrow'\n",
      " 'Arachnophobia' 'Vaccine' 'Arena' 'Dog Adventure' 'Awaken' 'Yesterday'\n",
      " 'Liminal' 'Ashes' 'Solitaire' 'Alone' 'Chaos' 'Stranded' 'City Z'\n",
      " 'Sleep Tight' 'Ceres' 'VOID' 'Cortex' 'Martial Law' 'Snapshot' 'Loop'\n",
      " 'Archipelago' 'Arboreal' 'Obscura' 'Space Survival' 'Police Chase'\n",
      " 'Fireflies' 'New York Bus Simulator' 'DEFECTIVE' 'Nightfall'\n",
      " 'The Legend of Heroes: Kuro no Kiseki' 'The Visitor' 'Survivor' 'Bonfire'\n",
      " 'Captive' 'Daddy' 'Equinox' 'Escape Room' 'Achromatic' 'Bottle' 'Eidolon'\n",
      " 'My Pet Rock' 'Swarm' 'Entangled' 'Personal Space' 'Escape' 'Between']\n"
     ]
    }
   ],
   "source": [
    "titulos_duplicados = final_df['title'].duplicated().sum()\n",
    "print(f\"Número de títulos duplicados: {titulos_duplicados}\")\n",
    "titulos_repetidos = final_df[final_df['title'].duplicated(keep=False)]['title'].unique()\n",
    "print(f\"Títulos duplicados: {titulos_repetidos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>date_release</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>price_final</th>\n",
       "      <th>price_original</th>\n",
       "      <th>discount</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>median_hours</th>\n",
       "      <th>std_hours</th>\n",
       "      <th>recommendation_ratio</th>\n",
       "      <th>avg_helpful</th>\n",
       "      <th>avg_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.047200e+04</td>\n",
       "      <td>50472</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>5.047200e+04</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "      <td>50472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.053253e+06</td>\n",
       "      <td>2019-03-10 18:46:25.164051456</td>\n",
       "      <td>77.107149</td>\n",
       "      <td>1.827487e+03</td>\n",
       "      <td>8.334297</td>\n",
       "      <td>8.418423</td>\n",
       "      <td>5.593557</td>\n",
       "      <td>2062.217764</td>\n",
       "      <td>11.961956</td>\n",
       "      <td>5.609096</td>\n",
       "      <td>21.154918</td>\n",
       "      <td>0.698100</td>\n",
       "      <td>2.921674</td>\n",
       "      <td>0.494605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1997-06-30 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.279475e+05</td>\n",
       "      <td>2017-03-17 00:00:00</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1141.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.840950e+05</td>\n",
       "      <td>2019-08-20 00:00:00</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>3.460451</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.203173</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>2.176318</td>\n",
       "      <td>0.131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.521705e+06</td>\n",
       "      <td>2021-09-17 00:00:00</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>11.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>10.753019</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.654140</td>\n",
       "      <td>0.881903</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.599300e+06</td>\n",
       "      <td>2023-10-24 00:00:00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.494460e+06</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>9986.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>511.500000</td>\n",
       "      <td>495.120177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>268.285714</td>\n",
       "      <td>266.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.095610e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.217559</td>\n",
       "      <td>4.018612e+04</td>\n",
       "      <td>9.882176</td>\n",
       "      <td>9.686554</td>\n",
       "      <td>18.599731</td>\n",
       "      <td>1125.329458</td>\n",
       "      <td>27.762187</td>\n",
       "      <td>16.033585</td>\n",
       "      <td>40.894435</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>4.688425</td>\n",
       "      <td>2.486727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             app_id                   date_release  positive_ratio  \\\n",
       "count  5.047200e+04                          50472    50472.000000   \n",
       "mean   1.053253e+06  2019-03-10 18:46:25.164051456       77.107149   \n",
       "min    1.000000e+01            1997-06-30 00:00:00        0.000000   \n",
       "25%    5.279475e+05            2017-03-17 00:00:00       67.000000   \n",
       "50%    9.840950e+05            2019-08-20 00:00:00       81.000000   \n",
       "75%    1.521705e+06            2021-09-17 00:00:00       91.000000   \n",
       "max    2.599300e+06            2023-10-24 00:00:00      100.000000   \n",
       "std    6.095610e+05                            NaN       18.217559   \n",
       "\n",
       "       user_reviews   price_final  price_original      discount  \\\n",
       "count  5.047200e+04  50472.000000    50472.000000  50472.000000   \n",
       "mean   1.827487e+03      8.334297        8.418423      5.593557   \n",
       "min    1.000000e+01      0.000000        0.000000      0.000000   \n",
       "25%    1.900000e+01      0.990000        0.990000      0.000000   \n",
       "50%    4.900000e+01      4.990000        4.990000      0.000000   \n",
       "75%    2.080000e+02     10.990000       11.990000      0.000000   \n",
       "max    7.494460e+06     70.000000       69.990000     90.000000   \n",
       "std    4.018612e+04      9.882176        9.686554     18.599731   \n",
       "\n",
       "       days_in_market     avg_hours  median_hours     std_hours  \\\n",
       "count    50472.000000  50472.000000  50472.000000  50472.000000   \n",
       "mean      2062.217764     11.961956      5.609096     21.154918   \n",
       "min        374.000000      0.000000      0.000000      0.000000   \n",
       "25%       1141.000000      0.000000      0.000000      0.000000   \n",
       "50%       1900.000000      3.460451      1.500000      4.203173   \n",
       "75%       2786.000000     10.753019      5.000000     21.654140   \n",
       "max       9986.000000    487.000000    511.500000    495.120177   \n",
       "std       1125.329458     27.762187     16.033585     40.894435   \n",
       "\n",
       "       recommendation_ratio   avg_helpful     avg_funny  \n",
       "count          50472.000000  50472.000000  50472.000000  \n",
       "mean               0.698100      2.921674      0.494605  \n",
       "min                0.000000      0.000000      0.000000  \n",
       "25%                0.500000      0.000000      0.000000  \n",
       "50%                0.716655      2.176318      0.131313  \n",
       "75%                0.881903      4.000000      0.480000  \n",
       "max                1.000000    268.285714    266.285714  \n",
       "std                0.204009      4.688425      2.486727  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_unicos = ~final_df['title'].duplicated(keep=False)\n",
    "\n",
    "# Filtrar el DataFrame para conservar solo los títulos únicos\n",
    "final_df = final_df[titulos_unicos].reset_index(drop=True)\n",
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de títulos duplicados: 0\n",
      "Títulos duplicados: []\n"
     ]
    }
   ],
   "source": [
    "titulos_duplicados = final_df['title'].duplicated().sum()\n",
    "print(f\"Número de títulos duplicados: {titulos_duplicados}\")\n",
    "titulos_repetidos = final_df[final_df['title'].duplicated(keep=False)]['title'].unique()\n",
    "print(f\"Títulos duplicados: {titulos_repetidos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos las features que se usarán para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'price_final', 'price_original', 'discount',\n",
    "    'win', 'mac', 'linux', 'steam_deck',\n",
    "    'days_in_market',\n",
    "    'avg_hours', 'median_hours', 'std_hours',\n",
    "    'recommendation_ratio', 'avg_helpful', 'avg_funny'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por los valores tan diferentes que tenemos en el dataset, normalizamos los datos para que puedan ser usados por el modelo sin problemas y no haya valores extremos que hagan que los valores menores no tengan importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_features = [\n",
    "    'price_final', 'price_original', 'discount',\n",
    "    'days_in_market', 'avg_hours', 'median_hours', 'std_hours',\n",
    "    'recommendation_ratio', 'avg_helpful', 'avg_funny'\n",
    "]\n",
    "final_df[numeric_features] = scaler.fit_transform(final_df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos la compatibilidad con diferentes plataformas a que sean booleanas, 0 o 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = ['win', 'mac', 'linux', 'steam_deck']\n",
    "final_df[bool_features] = final_df[bool_features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos la variable dependiente (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(final_df['rating'])\n",
    "y = label_encoder.fit_transform(final_df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos las features (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiamos los títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    \"\"\"\n",
    "    Limpia y normaliza el título del juego.\n",
    "    \n",
    "    Args:\n",
    "        title (str): Título original del juego\n",
    "        \n",
    "    Returns:\n",
    "        str: Título limpio y normalizado\n",
    "    \"\"\"\n",
    "    # Convertir a minúsculas\n",
    "    title = title.lower()\n",
    "    \n",
    "    # Eliminar caracteres especiales y símbolos, manteniendo espacios\n",
    "    title = re.sub(r'[^\\w\\s]', ' ', title)\n",
    "    \n",
    "    # Eliminar espacios múltiples\n",
    "    title = ' '.join(title.split())\n",
    "    \n",
    "    return title\n",
    "\n",
    "# Aplicar la limpieza a los títulos\n",
    "final_df['clean_title'] = final_df['title'].apply(clean_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos y configuramos el tokenizer (TorchText no me funciona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, num_words=10000, oov_token='<OOV>'):\n",
    "        self.num_words = num_words\n",
    "        self.oov_token = oov_token\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "        self.word_counts = {}\n",
    "        \n",
    "    def fit_on_texts(self, texts):\n",
    "        # Contar todas las palabras\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                self.word_counts[word] = self.word_counts.get(word, 0) + 1\n",
    "        \n",
    "        # Ordenar por frecuencia y tomar los num_words más frecuentes\n",
    "        sorted_words = sorted(self.word_counts.items(), \n",
    "                            key=lambda x: x[1], \n",
    "                            reverse=True)[:self.num_words-1]\n",
    "        \n",
    "        # Crear mappings\n",
    "        self.word_index = {self.oov_token: 0}\n",
    "        self.index_word = {0: self.oov_token}\n",
    "        \n",
    "        for idx, (word, _) in enumerate(sorted_words, 1):\n",
    "            self.word_index[word] = idx\n",
    "            self.index_word[idx] = word\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = []\n",
    "            for word in text.split():\n",
    "                sequence.append(self.word_index.get(word, 0))  # 0 es OOV\n",
    "            sequences.append(sequence)\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para hacer padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_len=None, padding_value=0):\n",
    "    \"\"\"\n",
    "    Hace padding de las secuencias a una longitud máxima\n",
    "    \"\"\"\n",
    "    if max_len is None:\n",
    "        max_len = max(len(seq) for seq in sequences)\n",
    "    \n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > max_len:\n",
    "            padded_sequences.append(seq[:max_len])\n",
    "        else:\n",
    "            padded_sequences.append(seq + [padding_value] * (max_len - len(seq)))\n",
    "    \n",
    "    return torch.tensor(padded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos la tokenización y el padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la tokenización y padding\n",
    "tokenizer = SimpleTokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(final_df['clean_title'])\n",
    "sequences = tokenizer.texts_to_sequences(final_df['clean_title'])\n",
    "padded_sequences = pad_sequences(sequences, max_len=10)  # Usamos max_len=10 como en tu código original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de las secuencias padding: torch.Size([50472, 10])\n",
      "Tamaño del vocabulario: 10000\n",
      "\n",
      "Ejemplo de tokenización:\n",
      "Texto original: prince of persia warrior within\n",
      "Secuencia tokenizada: [1275, 2, 2533, 243, 657]\n",
      "Secuencia con padding: [1275, 2, 2533, 243, 657, 0, 0, 0, 0, 0]\n",
      "\n",
      "Variables importantes:\n",
      "Máxima longitud de secuencia: 10\n",
      "Dimensión del embedding: 32\n",
      "Tamaño del vocabulario: 10000\n"
     ]
    }
   ],
   "source": [
    "# Veamos algunos stats\n",
    "print(f\"Forma de las secuencias padding: {padded_sequences.shape}\")\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "print(f\"Tamaño del vocabulario: {vocab_size}\")\n",
    "\n",
    "# Veamos un ejemplo\n",
    "example_idx = 0\n",
    "print(\"\\nEjemplo de tokenización:\")\n",
    "print(f\"Texto original: {final_df['clean_title'].iloc[example_idx]}\")\n",
    "print(f\"Secuencia tokenizada: {sequences[example_idx]}\")\n",
    "print(f\"Secuencia con padding: {padded_sequences[example_idx].tolist()}\")\n",
    "\n",
    "# Guardamos algunas variables importantes para el modelo\n",
    "max_length = padded_sequences.shape[1]  # Longitud máxima de las secuencias\n",
    "embedding_dim = 32  # Dimensión del embedding (igual que en tu código original)\n",
    "\n",
    "print(f\"\\nVariables importantes:\")\n",
    "print(f\"Máxima longitud de secuencia: {max_length}\")\n",
    "print(f\"Dimensión del embedding: {embedding_dim}\")\n",
    "print(f\"Tamaño del vocabulario: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date_release</th>\n",
       "      <th>win</th>\n",
       "      <th>mac</th>\n",
       "      <th>linux</th>\n",
       "      <th>rating</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>price_final</th>\n",
       "      <th>price_original</th>\n",
       "      <th>discount</th>\n",
       "      <th>steam_deck</th>\n",
       "      <th>days_in_market</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>median_hours</th>\n",
       "      <th>std_hours</th>\n",
       "      <th>recommendation_ratio</th>\n",
       "      <th>avg_helpful</th>\n",
       "      <th>avg_funny</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>Prince of Persia: Warrior Within™</td>\n",
       "      <td>2008-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>84</td>\n",
       "      <td>2199</td>\n",
       "      <td>0.167546</td>\n",
       "      <td>0.162245</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>3.342861</td>\n",
       "      <td>0.252359</td>\n",
       "      <td>0.454731</td>\n",
       "      <td>0.502943</td>\n",
       "      <td>0.723937</td>\n",
       "      <td>0.526915</td>\n",
       "      <td>0.047249</td>\n",
       "      <td>prince of persia warrior within</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22364</td>\n",
       "      <td>BRINK: Agents of Change</td>\n",
       "      <td>2011-08-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.540807</td>\n",
       "      <td>-0.560414</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>2.467553</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>brink agents of change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113020</td>\n",
       "      <td>Monaco: What's Yours Is Mine</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>92</td>\n",
       "      <td>3722</td>\n",
       "      <td>0.673512</td>\n",
       "      <td>0.678429</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>1.907711</td>\n",
       "      <td>0.304422</td>\n",
       "      <td>0.080513</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>1.031535</td>\n",
       "      <td>-0.317165</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>monaco what s yours is mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226560</td>\n",
       "      <td>Escape Dead Island</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>61</td>\n",
       "      <td>873</td>\n",
       "      <td>0.673512</td>\n",
       "      <td>0.678429</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>1.398522</td>\n",
       "      <td>-0.042696</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>-0.140193</td>\n",
       "      <td>-0.353433</td>\n",
       "      <td>0.822697</td>\n",
       "      <td>0.128956</td>\n",
       "      <td>escape dead island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249050</td>\n",
       "      <td>Dungeon of the ENDLESS™</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>88</td>\n",
       "      <td>8784</td>\n",
       "      <td>0.369933</td>\n",
       "      <td>0.368719</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>1.418072</td>\n",
       "      <td>1.032340</td>\n",
       "      <td>1.109613</td>\n",
       "      <td>0.824208</td>\n",
       "      <td>0.918921</td>\n",
       "      <td>-0.083344</td>\n",
       "      <td>0.081934</td>\n",
       "      <td>dungeon of the endless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50467</th>\n",
       "      <td>2296380</td>\n",
       "      <td>I Expect You To Die 3: Cog in the Machine</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>96</td>\n",
       "      <td>101</td>\n",
       "      <td>1.382877</td>\n",
       "      <td>-0.869092</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.477109</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>i expect you to die 3 cog in the machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50468</th>\n",
       "      <td>1272080</td>\n",
       "      <td>PAYDAY 3</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mostly Negative</td>\n",
       "      <td>38</td>\n",
       "      <td>29458</td>\n",
       "      <td>3.204357</td>\n",
       "      <td>-0.869092</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.470889</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>payday 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50469</th>\n",
       "      <td>1402110</td>\n",
       "      <td>Eternights</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>89</td>\n",
       "      <td>1128</td>\n",
       "      <td>2.192424</td>\n",
       "      <td>-0.869092</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.462002</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>eternights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50470</th>\n",
       "      <td>2272250</td>\n",
       "      <td>Forgive Me Father 2</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>0.876911</td>\n",
       "      <td>-0.869092</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.495770</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>forgive me father 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50471</th>\n",
       "      <td>2488510</td>\n",
       "      <td>FatalZone</td>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>88</td>\n",
       "      <td>144</td>\n",
       "      <td>-0.438602</td>\n",
       "      <td>-0.869092</td>\n",
       "      <td>-0.300736</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.499325</td>\n",
       "      <td>-0.430877</td>\n",
       "      <td>-0.349838</td>\n",
       "      <td>-0.517311</td>\n",
       "      <td>-0.971047</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>-0.198900</td>\n",
       "      <td>fatalzone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50472 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        app_id                                      title date_release  win  \\\n",
       "0        13500          Prince of Persia: Warrior Within™   2008-11-21    1   \n",
       "1        22364                    BRINK: Agents of Change   2011-08-03    1   \n",
       "2       113020               Monaco: What's Yours Is Mine   2013-04-24    1   \n",
       "3       226560                         Escape Dead Island   2014-11-18    1   \n",
       "4       249050                    Dungeon of the ENDLESS™   2014-10-27    1   \n",
       "...        ...                                        ...          ...  ...   \n",
       "50467  2296380  I Expect You To Die 3: Cog in the Machine   2023-09-28    1   \n",
       "50468  1272080                                   PAYDAY 3   2023-09-21    1   \n",
       "50469  1402110                                 Eternights   2023-09-11    1   \n",
       "50470  2272250                        Forgive Me Father 2   2023-10-19    1   \n",
       "50471  2488510                                  FatalZone   2023-10-23    1   \n",
       "\n",
       "       mac  linux           rating  positive_ratio  user_reviews  price_final  \\\n",
       "0        0      0    Very Positive              84          2199     0.167546   \n",
       "1        0      0         Positive              85            21    -0.540807   \n",
       "2        1      1    Very Positive              92          3722     0.673512   \n",
       "3        0      0            Mixed              61           873     0.673512   \n",
       "4        1      0    Very Positive              88          8784     0.369933   \n",
       "...    ...    ...              ...             ...           ...          ...   \n",
       "50467    0      0    Very Positive              96           101     1.382877   \n",
       "50468    0      0  Mostly Negative              38         29458     3.204357   \n",
       "50469    0      0    Very Positive              89          1128     2.192424   \n",
       "50470    0      0    Very Positive              95            82     0.876911   \n",
       "50471    0      0    Very Positive              88           144    -0.438602   \n",
       "\n",
       "       price_original  discount  steam_deck  days_in_market  avg_hours  \\\n",
       "0            0.162245 -0.300736           1        3.342861   0.252359   \n",
       "1           -0.560414 -0.300736           1        2.467553  -0.430877   \n",
       "2            0.678429 -0.300736           1        1.907711   0.304422   \n",
       "3            0.678429 -0.300736           1        1.398522  -0.042696   \n",
       "4            0.368719 -0.300736           1        1.418072   1.032340   \n",
       "...               ...       ...         ...             ...        ...   \n",
       "50467       -0.869092 -0.300736           1       -1.477109  -0.430877   \n",
       "50468       -0.869092 -0.300736           1       -1.470889  -0.430877   \n",
       "50469       -0.869092 -0.300736           1       -1.462002  -0.430877   \n",
       "50470       -0.869092 -0.300736           1       -1.495770  -0.430877   \n",
       "50471       -0.869092 -0.300736           1       -1.499325  -0.430877   \n",
       "\n",
       "       median_hours  std_hours  recommendation_ratio  avg_helpful  avg_funny  \\\n",
       "0          0.454731   0.502943              0.723937     0.526915   0.047249   \n",
       "1         -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "2          0.080513   0.785937              1.031535    -0.317165  -0.017784   \n",
       "3          0.155357  -0.140193             -0.353433     0.822697   0.128956   \n",
       "4          1.109613   0.824208              0.918921    -0.083344   0.081934   \n",
       "...             ...        ...                   ...          ...        ...   \n",
       "50467     -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "50468     -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "50469     -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "50470     -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "50471     -0.349838  -0.517311             -0.971047    -0.623174  -0.198900   \n",
       "\n",
       "                                    clean_title  \n",
       "0               prince of persia warrior within  \n",
       "1                        brink agents of change  \n",
       "2                   monaco what s yours is mine  \n",
       "3                            escape dead island  \n",
       "4                        dungeon of the endless  \n",
       "...                                         ...  \n",
       "50467  i expect you to die 3 cog in the machine  \n",
       "50468                                  payday 3  \n",
       "50469                                eternights  \n",
       "50470                       forgive me father 2  \n",
       "50471                                 fatalzone  \n",
       "\n",
       "[50472 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 1 ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos los datos en Train 60%, Validation 20% y Test 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datos:\n",
      "X_train: (30282, 14)\n",
      "X_val: (10095, 14)\n",
      "X_test: (10095, 14)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en train/validation/test (60%/20%/20%)\n",
    "X_temp, X_test, y_temp, y_test, seq_temp, seq_test = train_test_split(\n",
    "    X, y, padded_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val, seq_train, seq_val = train_test_split(\n",
    "    X_temp, y_temp, seq_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones de los datos:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos a tensores de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a tensores de PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "seq_train = torch.LongTensor(seq_train)\n",
    "seq_val = torch.LongTensor(seq_val)\n",
    "seq_test = torch.LongTensor(seq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos el dataset personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameDataset(Dataset):\n",
    "    def __init__(self, features, sequences, labels):\n",
    "        self.features = features\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'sequence': self.sequences[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos los dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dataset = GameDataset(X_train, seq_train, y_train)\n",
    "val_dataset = GameDataset(X_val, seq_val, y_val)\n",
    "test_dataset = GameDataset(X_test, seq_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameRatingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_length, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding para los títulos\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Calculamos el tamaño del embedding aplanado\n",
    "        self.flat_embed_size = max_length * embedding_dim\n",
    "        \n",
    "        # Capa para features numéricas\n",
    "        self.numeric_layer = nn.Sequential(\n",
    "            nn.Linear(num_features, 64), # Reducimos las features a 64 dimensiones\n",
    "            nn.ReLU(), # Función de activación no lineal\n",
    "            nn.BatchNorm1d(64) # Normalización de las activaciones\n",
    "        )\n",
    "        \n",
    "        # Capas combinadas después de la concatenación\n",
    "        self.combined_layers = nn.Sequential(\n",
    "            nn.Linear(self.flat_embed_size + 64, 128), # Primera capa densa\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), # Evitamos overfitting\n",
    "            nn.BatchNorm1d(128),\n",
    "            \n",
    "            nn.Linear(128, 64), # Segunda capa densa\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            \n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, sequences, features):\n",
    "        # Procesar títulos\n",
    "        embedded = self.embedding(sequences)\n",
    "        flat_embedded = embedded.view(embedded.size(0), -1)\n",
    "        \n",
    "        # Procesar features numéricas\n",
    "        numeric_out = self.numeric_layer(features)\n",
    "        \n",
    "        # Combinar ambos caminos\n",
    "        combined = torch.cat((flat_embedded, numeric_out), dim=1)\n",
    "        \n",
    "        # Capas finales\n",
    "        return self.combined_layers(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GameRatingModel(\n",
    "    vocab_size=vocab_size,  # Del tokenizer\n",
    "    embedding_dim=32,\n",
    "    max_length=10,  # Longitud máxima de las secuencias\n",
    "    num_features=X_train.shape[1],\n",
    "    num_classes=len(label_encoder.classes_)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuramos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Only show progress bar for first and last epoch\n",
    "        if epoch <= 5 or epoch >= num_epochs-5:\n",
    "            iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training')\n",
    "        else:\n",
    "            iterator = train_loader\n",
    "        \n",
    "        for batch in iterator:\n",
    "            features = batch['features'].to(device)\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        train_loss = train_loss/len(train_loader)\n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['features'].to(device)\n",
    "                sequences = batch['sequence'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(sequences, features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 157.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "Train Loss: 1.8491 | Train Acc: 38.95%\n",
      "Val Loss: 1.5136 | Val Acc: 49.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 375.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:\n",
      "Train Loss: 1.3874 | Train Acc: 52.35%\n",
      "Val Loss: 1.2674 | Val Acc: 53.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 370.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:\n",
      "Train Loss: 1.2219 | Train Acc: 55.31%\n",
      "Val Loss: 1.1991 | Val Acc: 54.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 90.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:\n",
      "Train Loss: 1.1491 | Train Acc: 56.57%\n",
      "Val Loss: 1.1432 | Val Acc: 55.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 409.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:\n",
      "Train Loss: 1.0970 | Train Acc: 57.57%\n",
      "Val Loss: 1.1177 | Val Acc: 55.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 399.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:\n",
      "Train Loss: 1.0586 | Train Acc: 58.97%\n",
      "Val Loss: 1.1012 | Val Acc: 56.53%\n",
      "Epoch 7/50:\n",
      "Train Loss: 1.0381 | Train Acc: 59.48%\n",
      "Val Loss: 1.0921 | Val Acc: 56.05%\n",
      "Epoch 8/50:\n",
      "Train Loss: 1.0195 | Train Acc: 60.33%\n",
      "Val Loss: 1.1094 | Val Acc: 55.72%\n",
      "Epoch 9/50:\n",
      "Train Loss: 0.9997 | Train Acc: 60.70%\n",
      "Val Loss: 1.0891 | Val Acc: 56.43%\n",
      "Epoch 10/50:\n",
      "Train Loss: 0.9814 | Train Acc: 61.67%\n",
      "Val Loss: 1.0812 | Val Acc: 56.45%\n",
      "Epoch 11/50:\n",
      "Train Loss: 0.9636 | Train Acc: 62.25%\n",
      "Val Loss: 1.0871 | Val Acc: 56.59%\n",
      "Epoch 12/50:\n",
      "Train Loss: 0.9438 | Train Acc: 63.01%\n",
      "Val Loss: 1.0795 | Val Acc: 56.67%\n",
      "Epoch 13/50:\n",
      "Train Loss: 0.9351 | Train Acc: 63.81%\n",
      "Val Loss: 1.0869 | Val Acc: 57.12%\n",
      "Epoch 14/50:\n",
      "Train Loss: 0.9144 | Train Acc: 64.15%\n",
      "Val Loss: 1.1152 | Val Acc: 56.25%\n",
      "Epoch 15/50:\n",
      "Train Loss: 0.9054 | Train Acc: 64.59%\n",
      "Val Loss: 1.0954 | Val Acc: 56.53%\n",
      "Epoch 16/50:\n",
      "Train Loss: 0.8877 | Train Acc: 65.45%\n",
      "Val Loss: 1.0961 | Val Acc: 56.62%\n",
      "Epoch 17/50:\n",
      "Train Loss: 0.8661 | Train Acc: 66.28%\n",
      "Val Loss: 1.1262 | Val Acc: 56.64%\n",
      "Epoch 18/50:\n",
      "Train Loss: 0.8547 | Train Acc: 66.67%\n",
      "Val Loss: 1.1251 | Val Acc: 56.84%\n",
      "Epoch 19/50:\n",
      "Train Loss: 0.8377 | Train Acc: 67.38%\n",
      "Val Loss: 1.1314 | Val Acc: 56.43%\n",
      "Epoch 20/50:\n",
      "Train Loss: 0.8302 | Train Acc: 67.86%\n",
      "Val Loss: 1.1391 | Val Acc: 56.27%\n",
      "Epoch 21/50:\n",
      "Train Loss: 0.8121 | Train Acc: 68.19%\n",
      "Val Loss: 1.1582 | Val Acc: 56.23%\n",
      "Epoch 22/50:\n",
      "Train Loss: 0.7944 | Train Acc: 69.16%\n",
      "Val Loss: 1.1507 | Val Acc: 56.58%\n",
      "Epoch 23/50:\n",
      "Train Loss: 0.7799 | Train Acc: 69.99%\n",
      "Val Loss: 1.1707 | Val Acc: 56.21%\n",
      "Epoch 24/50:\n",
      "Train Loss: 0.7668 | Train Acc: 70.51%\n",
      "Val Loss: 1.2028 | Val Acc: 55.79%\n",
      "Epoch 25/50:\n",
      "Train Loss: 0.7612 | Train Acc: 70.77%\n",
      "Val Loss: 1.1977 | Val Acc: 56.61%\n",
      "Epoch 26/50:\n",
      "Train Loss: 0.7576 | Train Acc: 70.78%\n",
      "Val Loss: 1.2324 | Val Acc: 55.21%\n",
      "Epoch 27/50:\n",
      "Train Loss: 0.7378 | Train Acc: 71.61%\n",
      "Val Loss: 1.2131 | Val Acc: 56.55%\n",
      "Epoch 28/50:\n",
      "Train Loss: 0.7302 | Train Acc: 71.72%\n",
      "Val Loss: 1.2096 | Val Acc: 56.30%\n",
      "Epoch 29/50:\n",
      "Train Loss: 0.7140 | Train Acc: 72.32%\n",
      "Val Loss: 1.2788 | Val Acc: 55.77%\n",
      "Epoch 30/50:\n",
      "Train Loss: 0.7031 | Train Acc: 72.87%\n",
      "Val Loss: 1.2537 | Val Acc: 56.21%\n",
      "Epoch 31/50:\n",
      "Train Loss: 0.6926 | Train Acc: 73.31%\n",
      "Val Loss: 1.2738 | Val Acc: 56.05%\n",
      "Epoch 32/50:\n",
      "Train Loss: 0.6759 | Train Acc: 73.80%\n",
      "Val Loss: 1.3029 | Val Acc: 55.15%\n",
      "Epoch 33/50:\n",
      "Train Loss: 0.6690 | Train Acc: 74.06%\n",
      "Val Loss: 1.3097 | Val Acc: 56.02%\n",
      "Epoch 34/50:\n",
      "Train Loss: 0.6592 | Train Acc: 74.59%\n",
      "Val Loss: 1.3068 | Val Acc: 55.96%\n",
      "Epoch 35/50:\n",
      "Train Loss: 0.6453 | Train Acc: 75.14%\n",
      "Val Loss: 1.3145 | Val Acc: 55.35%\n",
      "Epoch 36/50:\n",
      "Train Loss: 0.6372 | Train Acc: 75.46%\n",
      "Val Loss: 1.3226 | Val Acc: 55.71%\n",
      "Epoch 37/50:\n",
      "Train Loss: 0.6286 | Train Acc: 75.91%\n",
      "Val Loss: 1.3915 | Val Acc: 55.54%\n",
      "Epoch 38/50:\n",
      "Train Loss: 0.6222 | Train Acc: 76.15%\n",
      "Val Loss: 1.3800 | Val Acc: 55.15%\n",
      "Epoch 39/50:\n",
      "Train Loss: 0.6112 | Train Acc: 76.55%\n",
      "Val Loss: 1.4061 | Val Acc: 55.60%\n",
      "Epoch 40/50:\n",
      "Train Loss: 0.6058 | Train Acc: 77.03%\n",
      "Val Loss: 1.4005 | Val Acc: 54.69%\n",
      "Epoch 41/50:\n",
      "Train Loss: 0.5992 | Train Acc: 77.18%\n",
      "Val Loss: 1.4203 | Val Acc: 54.95%\n",
      "Epoch 42/50:\n",
      "Train Loss: 0.5836 | Train Acc: 77.75%\n",
      "Val Loss: 1.4491 | Val Acc: 55.33%\n",
      "Epoch 43/50:\n",
      "Train Loss: 0.5806 | Train Acc: 77.95%\n",
      "Val Loss: 1.4618 | Val Acc: 55.29%\n",
      "Epoch 44/50:\n",
      "Train Loss: 0.5745 | Train Acc: 78.35%\n",
      "Val Loss: 1.4776 | Val Acc: 55.33%\n",
      "Epoch 45/50:\n",
      "Train Loss: 0.5636 | Train Acc: 78.43%\n",
      "Val Loss: 1.4958 | Val Acc: 54.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 401.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50:\n",
      "Train Loss: 0.5637 | Train Acc: 78.53%\n",
      "Val Loss: 1.4854 | Val Acc: 54.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 391.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50:\n",
      "Train Loss: 0.5483 | Train Acc: 78.81%\n",
      "Val Loss: 1.5450 | Val Acc: 54.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 345.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50:\n",
      "Train Loss: 0.5410 | Train Acc: 79.33%\n",
      "Val Loss: 1.5534 | Val Acc: 54.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 383.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50:\n",
      "Train Loss: 0.5350 | Train Acc: 79.71%\n",
      "Val Loss: 1.5531 | Val Acc: 54.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Training: 100%|██████████| 61/61 [00:00<00:00, 383.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50:\n",
      "Train Loss: 0.5230 | Train Acc: 80.03%\n",
      "Val Loss: 1.5686 | Val Acc: 54.54%\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando entrenamiento...\")\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 56.71%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        features = batch['features'].to(device)\n",
    "        sequences = batch['sequence'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(sequences, features)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100.*test_correct/test_total\n",
    "print(f'\\nTest Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/first-model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training accuracy llega a un 80% aproximadamente\n",
    "- Validation accuracy se mantiene entre un 50% y un 60%\n",
    "- Test accuracy llega a un 55%\n",
    "\n",
    "Se presenta una clara señal de overfitting, el modelo no maneja bien los datos nuevos que recibe. Este se aprende muy bien los datos con los que entrena, sin embargo no es capáz de predecir correctamente los datos que no ha visto antes (validation y test). Sin embargo, desde el inicio la validation se mantiene por el 50%, no importa todo el entrenamiento no se mejora la validación, esto puede presentar que el modelo es muy simple para el problema en cuestión. \n",
    "\n",
    "(Esto es malo)\n",
    "- La arquitectura del modelo parece ser muy simple para el problema en cuestión\n",
    "- A pesar de esto, solo aprende sobre el train dataset creando overfitting, nunca logra que la validation pase el 60%\n",
    "- El batch size podría ser muy pequeño\n",
    "- El embedding podría ser de una dimensión muy pequeña para captuar toda la información de los títulos\n",
    "\n",
    "(Esto es bueno)\n",
    "- Entre 9 clases, donde adivinar de manera aleatoria sería con un 11% de probabilidad, el modelo logra predecir correctamente el 50% de las veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2 (Mejorado) ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datos:\n",
      "X_train: (30282, 14)\n",
      "X_val: (10095, 14)\n",
      "X_test: (10095, 14)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en train/validation/test (70%/20%/10%)\n",
    "X_temp, X_test, y_temp, y_test, seq_temp, seq_test = train_test_split(\n",
    "    X, y, padded_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val, seq_train, seq_val = train_test_split(\n",
    "    X_temp, y_temp, seq_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones de los datos:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a tensores de PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "seq_train = torch.LongTensor(seq_train)\n",
    "seq_val = torch.LongTensor(seq_val)\n",
    "seq_test = torch.LongTensor(seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RobustScaler:\n",
    "    def __init__(self):\n",
    "        self.q1 = None\n",
    "        self.q3 = None\n",
    "        self.iqr = None\n",
    "        self.median = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.q1 = np.percentile(data, 25, axis=0)\n",
    "        self.q3 = np.percentile(data, 75, axis=0)\n",
    "        self.iqr = self.q3 - self.q1\n",
    "        self.median = np.median(data, axis=0)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return (data - self.median) / (self.iqr + 1e-8)\n",
    "\n",
    "# Aplicar a las features numéricas\n",
    "numeric_features = [\n",
    "    'price_final', 'price_original', 'discount',\n",
    "    'days_in_market', 'avg_hours', 'median_hours', 'std_hours',\n",
    "    'recommendation_ratio', 'avg_helpful', 'avg_funny'\n",
    "]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(final_df[numeric_features])\n",
    "final_df[numeric_features] = scaler.transform(final_df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementamos residual block para que el gradiente pueda fluir por las capas sin que llegue a las últimas y haga cambios insignificantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        return self.norm(x + attn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumentamos el número de capas para permitir que el modelo pueda aprender más información\n",
    "### También aumentamos la dimensión del embedding de 32 a 128 para que esta pueda capturar toda la información de los títulos sin excepciones, realmente los títulos son muy cortos, pero de igual manera vale la pena intentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedGameRatingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_length, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding mejorado\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Procesamiento de títulos\n",
    "        self.title_dim = max_length * embedding_dim\n",
    "        self.title_processing = nn.Sequential(\n",
    "            nn.Linear(self.title_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Procesamiento numérico\n",
    "        self.numeric_processing = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Capas combinadas\n",
    "        combined_dim = 256 + 128\n",
    "        self.combined_layers = nn.Sequential(\n",
    "            ResidualBlock(combined_dim),\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            ResidualBlock(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, sequences, features):\n",
    "        # Procesar títulos\n",
    "        embedded = self.embedding(sequences)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        flat_embedded = embedded.reshape(embedded.size(0), -1)\n",
    "        title_features = self.title_processing(flat_embedded)\n",
    "        \n",
    "        # Procesar features numéricas\n",
    "        numeric_features = self.numeric_processing(features)\n",
    "        \n",
    "        # Combinar\n",
    "        combined = torch.cat((title_features, numeric_features), dim=1)\n",
    "        \n",
    "        # Capas finales\n",
    "        return self.combined_layers(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos early stopping para que el modelo se detenga durante el entrenamiento si detecta un retroceso considerable durante cierto número de épocas (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "    \n",
    "    def __call__(self, current_value, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = current_value\n",
    "            self.best_model = model.state_dict().copy()\n",
    "            return\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            if current_value < self.best_loss - self.min_delta:\n",
    "                self.best_loss = current_value\n",
    "                self.counter = 0\n",
    "                self.best_model = model.state_dict().copy()\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:  # mode == 'max'\n",
    "            if current_value > self.best_loss + self.min_delta:\n",
    "                self.best_loss = current_value\n",
    "                self.counter = 0\n",
    "                self.best_model = model.state_dict().copy()\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiamos de Adam a AdamW, lo que nos debería dar una mejor regularización\n",
    "### Disminuímos el learning rate y aumentamos el número de épocas para tener un entrenamiento más detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_improved_model(model, train_loader, val_loader, num_epochs=400):\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Calcular pesos de clase\n",
    "    class_counts = torch.bincount(y_train)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    class_weights = class_weights.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, mode='max')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            features = batch['features'].to(device)\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['features'].to(device)\n",
    "                sequences = batch['sequence'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(sequences, features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Métricas\n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping(val_acc, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            model.load_state_dict(early_stopping.best_model)\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/400: 100%|██████████| 61/61 [00:00<00:00, 313.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400:\n",
      "Train Loss: 1.0827 | Train Acc: 80.37%\n",
      "Val Loss: 2.5019 | Val Acc: 53.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/400: 100%|██████████| 61/61 [00:00<00:00, 348.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/400:\n",
      "Train Loss: 0.9047 | Train Acc: 80.00%\n",
      "Val Loss: 2.3997 | Val Acc: 53.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/400: 100%|██████████| 61/61 [00:00<00:00, 353.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/400:\n",
      "Train Loss: 0.8484 | Train Acc: 79.61%\n",
      "Val Loss: 2.3529 | Val Acc: 53.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/400: 100%|██████████| 61/61 [00:00<00:00, 360.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/400:\n",
      "Train Loss: 0.8123 | Train Acc: 79.51%\n",
      "Val Loss: 2.2978 | Val Acc: 53.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/400: 100%|██████████| 61/61 [00:00<00:00, 343.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/400:\n",
      "Train Loss: 0.8225 | Train Acc: 79.36%\n",
      "Val Loss: 2.3072 | Val Acc: 52.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/400: 100%|██████████| 61/61 [00:00<00:00, 349.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/400:\n",
      "Train Loss: 0.8189 | Train Acc: 79.00%\n",
      "Val Loss: 2.2858 | Val Acc: 52.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/400: 100%|██████████| 61/61 [00:00<00:00, 346.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/400:\n",
      "Train Loss: 0.7720 | Train Acc: 78.82%\n",
      "Val Loss: 2.2579 | Val Acc: 52.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/400: 100%|██████████| 61/61 [00:00<00:00, 278.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/400:\n",
      "Train Loss: 0.7505 | Train Acc: 78.50%\n",
      "Val Loss: 2.2780 | Val Acc: 52.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/400: 100%|██████████| 61/61 [00:00<00:00, 350.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/400:\n",
      "Train Loss: 0.7290 | Train Acc: 78.90%\n",
      "Val Loss: 2.2942 | Val Acc: 52.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/400: 100%|██████████| 61/61 [00:00<00:00, 88.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/400:\n",
      "Train Loss: 0.7356 | Train Acc: 79.12%\n",
      "Val Loss: 2.2933 | Val Acc: 52.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/400: 100%|██████████| 61/61 [00:00<00:00, 344.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/400:\n",
      "Train Loss: 0.7583 | Train Acc: 78.74%\n",
      "Val Loss: 2.2408 | Val Acc: 52.44%\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "config = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': 256,\n",
    "    'max_length': 10,\n",
    "    'num_features': X_train.shape[1],\n",
    "    'num_classes': len(label_encoder.classes_)\n",
    "}\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model2 = ImprovedGameRatingModel(**config).to(device)\n",
    "model2 = train_improved_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 54.25%\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        features = batch['features'].to(device)\n",
    "        sequences = batch['sequence'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(sequences, features)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100.*test_correct/test_total\n",
    "print(f'\\nTest Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), 'models/second-model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación modelo 2\n",
    "## Me lleva... empeoró"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training accuracy llega a un 80% aproximadamente\n",
    "- Validation accuracy se mantiene cerca del 50%\n",
    "- Test accuracy cerca del 50%\n",
    "\n",
    "De nuevo una señal clara de overfitting, pero ahora con ligeramente peores resultados en la validación y en las pruebas.\n",
    "\n",
    "(Esto es malo)\n",
    "- Parece ser que los cambios en la arquitectura del modelo no mejoraron el aprendizaje con respecto a los datos que no ha visto\n",
    "- Cambiar el embedding tampoco ayudó de nada, igual puede que los títulos no afecten en nada o muy poco a la calificación que tendrá un videojuego\n",
    "\n",
    "(Esto es bueno, sigue exactamente igual)\n",
    "- Entre 9 clases, donde adivinar de manera aleatoria sería con un 11% de probabilidad, el modelo logra predecir correctamente el 50% de las veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 3 (A ver si haciéndolo más simple logro algo) ------------------------------------\n",
    "## Se quita el autofrenado y agregamos dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datos:\n",
      "X_train: (30282, 14)\n",
      "X_val: (10095, 14)\n",
      "X_test: (10095, 14)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en train/validation/test (60%/20%/20%)\n",
    "X_temp, X_test, y_temp, y_test, seq_temp, seq_test = train_test_split(\n",
    "    X, y, padded_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val, seq_train, seq_val = train_test_split(\n",
    "    X_temp, y_temp, seq_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones de los datos:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a tensores de PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "seq_train = torch.LongTensor(seq_train)\n",
    "seq_val = torch.LongTensor(seq_val)\n",
    "seq_test = torch.LongTensor(seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameDataset(Dataset):\n",
    "    def __init__(self, features, sequences, labels):\n",
    "        self.features = features\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'sequence': self.sequences[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponemos el batch_size en 70 para que no sea muy bajo ni muy elevado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 70\n",
    "train_dataset = GameDataset(X_train, seq_train, y_train)\n",
    "val_dataset = GameDataset(X_val, seq_val, y_val)\n",
    "test_dataset = GameDataset(X_test, seq_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos una tercera capa densa nada más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameRatingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_length, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding para los títulos con dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = nn.Dropout(0.2)  # Dropout después del embedding\n",
    "        \n",
    "        # Calculamos el tamaño del embedding aplanado\n",
    "        self.flat_embed_size = max_length * embedding_dim\n",
    "        \n",
    "        # Capa para features numéricas con más dropout\n",
    "        self.numeric_layer = nn.Sequential(\n",
    "            nn.Dropout(0.1),  # Dropout inicial para features numéricas\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Dropout después de la activación\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \n",
    "        # Capas combinadas con dropout progresivo\n",
    "        self.combined_layers = nn.Sequential(\n",
    "            nn.Dropout(0.3),  # Dropout inicial para features combinadas\n",
    "            nn.Linear(self.flat_embed_size + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Aumentamos el dropout en capas más profundas\n",
    "            nn.BatchNorm1d(64),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Alto dropout en la última capa oculta\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, sequences, features):\n",
    "        # Procesar títulos con dropout\n",
    "        embedded = self.embedding(sequences)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        flat_embedded = embedded.view(embedded.size(0), -1)\n",
    "        \n",
    "        # Procesar features numéricas\n",
    "        numeric_out = self.numeric_layer(features)\n",
    "        \n",
    "        # Combinar ambos caminos\n",
    "        combined = torch.cat((flat_embedded, numeric_out), dim=1)\n",
    "        \n",
    "        # Capas finales\n",
    "        return self.combined_layers(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bajamos la dimensión del embedding a 16 en vista de lo cortos que son los títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model3 = GameRatingModel(\n",
    "    vocab_size=vocab_size,  # Del tokenizer\n",
    "    embedding_dim=16,\n",
    "    max_length=10,  # Longitud máxima de las secuencias\n",
    "    num_features=X_train.shape[1],\n",
    "    num_classes=len(label_encoder.classes_)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    best_model_state = None\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()  # Activa explícitamente el modo de entrenamiento (dropout activo)\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        if epoch <= 5 or epoch >= num_epochs-5:\n",
    "            iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training')\n",
    "        else:\n",
    "            iterator = train_loader\n",
    "        \n",
    "        for batch in iterator:\n",
    "            features = batch['features'].to(device)\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Opcional: gradient clipping para estabilidad\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        train_loss = train_loss/len(train_loader)\n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Desactiva explícitamente el dropout para validación\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['features'].to(device)\n",
    "                sequences = batch['sequence'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(sequences, features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        \n",
    "        # Guardar el mejor modelo basado en la precisión de validación\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Restaurar el mejor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumentamos las épocas a 150, más que el primer modelo\n",
    "### Cabe mencionar que se removió el frenado automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 739.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150:\n",
      "Train Loss: 0.7373 | Train Acc: 72.04%\n",
      "Val Loss: 1.3983 | Val Acc: 55.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 725.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150:\n",
      "Train Loss: 0.7419 | Train Acc: 71.54%\n",
      "Val Loss: 1.3520 | Val Acc: 55.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 711.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150:\n",
      "Train Loss: 0.7283 | Train Acc: 72.17%\n",
      "Val Loss: 1.3349 | Val Acc: 55.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 764.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150:\n",
      "Train Loss: 0.7294 | Train Acc: 72.15%\n",
      "Val Loss: 1.3290 | Val Acc: 54.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 749.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150:\n",
      "Train Loss: 0.7165 | Train Acc: 72.83%\n",
      "Val Loss: 1.3296 | Val Acc: 55.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 746.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150:\n",
      "Train Loss: 0.6988 | Train Acc: 73.25%\n",
      "Val Loss: 1.3509 | Val Acc: 54.39%\n",
      "Epoch 7/150:\n",
      "Train Loss: 0.6875 | Train Acc: 73.61%\n",
      "Val Loss: 1.3287 | Val Acc: 55.70%\n",
      "Epoch 8/150:\n",
      "Train Loss: 0.6705 | Train Acc: 74.25%\n",
      "Val Loss: 1.4269 | Val Acc: 54.34%\n",
      "Epoch 9/150:\n",
      "Train Loss: 0.6665 | Train Acc: 74.60%\n",
      "Val Loss: 1.3793 | Val Acc: 54.81%\n",
      "Epoch 10/150:\n",
      "Train Loss: 0.6480 | Train Acc: 75.45%\n",
      "Val Loss: 1.3834 | Val Acc: 54.98%\n",
      "Epoch 11/150:\n",
      "Train Loss: 0.6525 | Train Acc: 75.46%\n",
      "Val Loss: 1.4264 | Val Acc: 54.64%\n",
      "Epoch 12/150:\n",
      "Train Loss: 0.6518 | Train Acc: 75.20%\n",
      "Val Loss: 1.4606 | Val Acc: 53.63%\n",
      "Epoch 13/150:\n",
      "Train Loss: 0.6468 | Train Acc: 75.56%\n",
      "Val Loss: 1.4508 | Val Acc: 54.32%\n",
      "Epoch 14/150:\n",
      "Train Loss: 0.6287 | Train Acc: 76.08%\n",
      "Val Loss: 1.4537 | Val Acc: 54.56%\n",
      "Epoch 15/150:\n",
      "Train Loss: 0.6237 | Train Acc: 76.23%\n",
      "Val Loss: 1.4516 | Val Acc: 53.89%\n",
      "Epoch 16/150:\n",
      "Train Loss: 0.6018 | Train Acc: 77.01%\n",
      "Val Loss: 1.5365 | Val Acc: 54.04%\n",
      "Epoch 17/150:\n",
      "Train Loss: 0.5920 | Train Acc: 77.70%\n",
      "Val Loss: 1.5024 | Val Acc: 53.35%\n",
      "Epoch 18/150:\n",
      "Train Loss: 0.5889 | Train Acc: 77.47%\n",
      "Val Loss: 1.4819 | Val Acc: 53.90%\n",
      "Epoch 19/150:\n",
      "Train Loss: 0.5746 | Train Acc: 78.08%\n",
      "Val Loss: 1.5686 | Val Acc: 53.64%\n",
      "Epoch 20/150:\n",
      "Train Loss: 0.5686 | Train Acc: 78.18%\n",
      "Val Loss: 1.5653 | Val Acc: 53.39%\n",
      "Epoch 21/150:\n",
      "Train Loss: 0.5557 | Train Acc: 79.10%\n",
      "Val Loss: 1.5680 | Val Acc: 54.00%\n",
      "Epoch 22/150:\n",
      "Train Loss: 0.5533 | Train Acc: 79.05%\n",
      "Val Loss: 1.5903 | Val Acc: 53.91%\n",
      "Epoch 23/150:\n",
      "Train Loss: 0.5390 | Train Acc: 79.67%\n",
      "Val Loss: 1.5971 | Val Acc: 54.10%\n",
      "Epoch 24/150:\n",
      "Train Loss: 0.5323 | Train Acc: 79.95%\n",
      "Val Loss: 1.6269 | Val Acc: 53.06%\n",
      "Epoch 25/150:\n",
      "Train Loss: 0.5299 | Train Acc: 79.89%\n",
      "Val Loss: 1.5928 | Val Acc: 53.78%\n",
      "Epoch 26/150:\n",
      "Train Loss: 0.5284 | Train Acc: 79.94%\n",
      "Val Loss: 1.6763 | Val Acc: 53.72%\n",
      "Epoch 27/150:\n",
      "Train Loss: 0.5085 | Train Acc: 80.86%\n",
      "Val Loss: 1.6525 | Val Acc: 53.99%\n",
      "Epoch 28/150:\n",
      "Train Loss: 0.5025 | Train Acc: 81.35%\n",
      "Val Loss: 1.6639 | Val Acc: 53.54%\n",
      "Epoch 29/150:\n",
      "Train Loss: 0.4965 | Train Acc: 81.26%\n",
      "Val Loss: 1.7040 | Val Acc: 54.50%\n",
      "Epoch 30/150:\n",
      "Train Loss: 0.4985 | Train Acc: 81.47%\n",
      "Val Loss: 1.7258 | Val Acc: 53.50%\n",
      "Epoch 31/150:\n",
      "Train Loss: 0.4910 | Train Acc: 81.48%\n",
      "Val Loss: 1.7481 | Val Acc: 53.83%\n",
      "Epoch 32/150:\n",
      "Train Loss: 0.4841 | Train Acc: 81.79%\n",
      "Val Loss: 1.7470 | Val Acc: 53.91%\n",
      "Epoch 33/150:\n",
      "Train Loss: 0.4695 | Train Acc: 82.28%\n",
      "Val Loss: 1.7476 | Val Acc: 53.30%\n",
      "Epoch 34/150:\n",
      "Train Loss: 0.4734 | Train Acc: 82.12%\n",
      "Val Loss: 1.7181 | Val Acc: 53.59%\n",
      "Epoch 35/150:\n",
      "Train Loss: 0.4553 | Train Acc: 82.85%\n",
      "Val Loss: 1.8372 | Val Acc: 53.37%\n",
      "Epoch 36/150:\n",
      "Train Loss: 0.4614 | Train Acc: 82.64%\n",
      "Val Loss: 1.7751 | Val Acc: 53.38%\n",
      "Epoch 37/150:\n",
      "Train Loss: 0.4535 | Train Acc: 83.04%\n",
      "Val Loss: 1.8450 | Val Acc: 53.39%\n",
      "Epoch 38/150:\n",
      "Train Loss: 0.4459 | Train Acc: 83.38%\n",
      "Val Loss: 1.8531 | Val Acc: 52.96%\n",
      "Epoch 39/150:\n",
      "Train Loss: 0.4413 | Train Acc: 83.72%\n",
      "Val Loss: 1.8620 | Val Acc: 53.04%\n",
      "Epoch 40/150:\n",
      "Train Loss: 0.4376 | Train Acc: 83.54%\n",
      "Val Loss: 1.8924 | Val Acc: 52.82%\n",
      "Epoch 41/150:\n",
      "Train Loss: 0.4296 | Train Acc: 83.70%\n",
      "Val Loss: 1.8687 | Val Acc: 53.55%\n",
      "Epoch 42/150:\n",
      "Train Loss: 0.4361 | Train Acc: 83.75%\n",
      "Val Loss: 1.9230 | Val Acc: 53.54%\n",
      "Epoch 43/150:\n",
      "Train Loss: 0.4229 | Train Acc: 84.23%\n",
      "Val Loss: 1.8640 | Val Acc: 53.49%\n",
      "Epoch 44/150:\n",
      "Train Loss: 0.4191 | Train Acc: 84.26%\n",
      "Val Loss: 1.9773 | Val Acc: 52.41%\n",
      "Epoch 45/150:\n",
      "Train Loss: 0.4100 | Train Acc: 84.52%\n",
      "Val Loss: 1.9641 | Val Acc: 52.83%\n",
      "Epoch 46/150:\n",
      "Train Loss: 0.4128 | Train Acc: 84.55%\n",
      "Val Loss: 1.9450 | Val Acc: 52.77%\n",
      "Epoch 47/150:\n",
      "Train Loss: 0.4090 | Train Acc: 84.52%\n",
      "Val Loss: 1.9330 | Val Acc: 52.86%\n",
      "Epoch 48/150:\n",
      "Train Loss: 0.4093 | Train Acc: 84.75%\n",
      "Val Loss: 1.9714 | Val Acc: 52.78%\n",
      "Epoch 49/150:\n",
      "Train Loss: 0.4029 | Train Acc: 85.01%\n",
      "Val Loss: 2.0254 | Val Acc: 52.85%\n",
      "Epoch 50/150:\n",
      "Train Loss: 0.3960 | Train Acc: 85.06%\n",
      "Val Loss: 2.0240 | Val Acc: 52.67%\n",
      "Epoch 51/150:\n",
      "Train Loss: 0.3911 | Train Acc: 85.41%\n",
      "Val Loss: 2.0007 | Val Acc: 52.98%\n",
      "Epoch 52/150:\n",
      "Train Loss: 0.3874 | Train Acc: 85.57%\n",
      "Val Loss: 2.0049 | Val Acc: 53.17%\n",
      "Epoch 53/150:\n",
      "Train Loss: 0.3874 | Train Acc: 85.54%\n",
      "Val Loss: 2.0071 | Val Acc: 52.93%\n",
      "Epoch 54/150:\n",
      "Train Loss: 0.3747 | Train Acc: 85.84%\n",
      "Val Loss: 2.1096 | Val Acc: 53.22%\n",
      "Epoch 55/150:\n",
      "Train Loss: 0.3789 | Train Acc: 85.58%\n",
      "Val Loss: 2.0488 | Val Acc: 53.23%\n",
      "Epoch 56/150:\n",
      "Train Loss: 0.3815 | Train Acc: 85.63%\n",
      "Val Loss: 2.0834 | Val Acc: 52.21%\n",
      "Epoch 57/150:\n",
      "Train Loss: 0.3734 | Train Acc: 86.09%\n",
      "Val Loss: 2.0948 | Val Acc: 53.05%\n",
      "Epoch 58/150:\n",
      "Train Loss: 0.3632 | Train Acc: 86.60%\n",
      "Val Loss: 2.1424 | Val Acc: 52.81%\n",
      "Epoch 59/150:\n",
      "Train Loss: 0.3690 | Train Acc: 86.29%\n",
      "Val Loss: 2.1533 | Val Acc: 52.46%\n",
      "Epoch 60/150:\n",
      "Train Loss: 0.3609 | Train Acc: 86.48%\n",
      "Val Loss: 2.1486 | Val Acc: 53.04%\n",
      "Epoch 61/150:\n",
      "Train Loss: 0.3592 | Train Acc: 86.61%\n",
      "Val Loss: 2.1949 | Val Acc: 53.10%\n",
      "Epoch 62/150:\n",
      "Train Loss: 0.3508 | Train Acc: 86.78%\n",
      "Val Loss: 2.1786 | Val Acc: 52.71%\n",
      "Epoch 63/150:\n",
      "Train Loss: 0.3545 | Train Acc: 86.74%\n",
      "Val Loss: 2.0997 | Val Acc: 53.19%\n",
      "Epoch 64/150:\n",
      "Train Loss: 0.3567 | Train Acc: 86.64%\n",
      "Val Loss: 2.1873 | Val Acc: 53.19%\n",
      "Epoch 65/150:\n",
      "Train Loss: 0.3476 | Train Acc: 87.14%\n",
      "Val Loss: 2.2050 | Val Acc: 52.14%\n",
      "Epoch 66/150:\n",
      "Train Loss: 0.3462 | Train Acc: 87.21%\n",
      "Val Loss: 2.2547 | Val Acc: 52.70%\n",
      "Epoch 67/150:\n",
      "Train Loss: 0.3461 | Train Acc: 87.26%\n",
      "Val Loss: 2.2192 | Val Acc: 52.60%\n",
      "Epoch 68/150:\n",
      "Train Loss: 0.3386 | Train Acc: 87.49%\n",
      "Val Loss: 2.3142 | Val Acc: 52.22%\n",
      "Epoch 69/150:\n",
      "Train Loss: 0.3343 | Train Acc: 87.46%\n",
      "Val Loss: 2.2428 | Val Acc: 52.62%\n",
      "Epoch 70/150:\n",
      "Train Loss: 0.3365 | Train Acc: 87.59%\n",
      "Val Loss: 2.2763 | Val Acc: 52.75%\n",
      "Epoch 71/150:\n",
      "Train Loss: 0.3315 | Train Acc: 87.72%\n",
      "Val Loss: 2.3413 | Val Acc: 52.49%\n",
      "Epoch 72/150:\n",
      "Train Loss: 0.3306 | Train Acc: 87.69%\n",
      "Val Loss: 2.2814 | Val Acc: 53.06%\n",
      "Epoch 73/150:\n",
      "Train Loss: 0.3296 | Train Acc: 87.69%\n",
      "Val Loss: 2.2908 | Val Acc: 52.60%\n",
      "Epoch 74/150:\n",
      "Train Loss: 0.3347 | Train Acc: 87.70%\n",
      "Val Loss: 2.2973 | Val Acc: 52.60%\n",
      "Epoch 75/150:\n",
      "Train Loss: 0.3285 | Train Acc: 87.82%\n",
      "Val Loss: 2.3567 | Val Acc: 52.31%\n",
      "Epoch 76/150:\n",
      "Train Loss: 0.3168 | Train Acc: 88.07%\n",
      "Val Loss: 2.2652 | Val Acc: 52.52%\n",
      "Epoch 77/150:\n",
      "Train Loss: 0.3167 | Train Acc: 88.09%\n",
      "Val Loss: 2.4071 | Val Acc: 52.31%\n",
      "Epoch 78/150:\n",
      "Train Loss: 0.3214 | Train Acc: 88.02%\n",
      "Val Loss: 2.3153 | Val Acc: 52.89%\n",
      "Epoch 79/150:\n",
      "Train Loss: 0.3159 | Train Acc: 88.27%\n",
      "Val Loss: 2.3820 | Val Acc: 52.74%\n",
      "Epoch 80/150:\n",
      "Train Loss: 0.3147 | Train Acc: 88.23%\n",
      "Val Loss: 2.3728 | Val Acc: 52.44%\n",
      "Epoch 81/150:\n",
      "Train Loss: 0.3206 | Train Acc: 87.90%\n",
      "Val Loss: 2.3499 | Val Acc: 51.94%\n",
      "Epoch 82/150:\n",
      "Train Loss: 0.3134 | Train Acc: 88.54%\n",
      "Val Loss: 2.3889 | Val Acc: 52.18%\n",
      "Epoch 83/150:\n",
      "Train Loss: 0.3094 | Train Acc: 88.44%\n",
      "Val Loss: 2.4072 | Val Acc: 52.17%\n",
      "Epoch 84/150:\n",
      "Train Loss: 0.3052 | Train Acc: 88.78%\n",
      "Val Loss: 2.3797 | Val Acc: 52.68%\n",
      "Epoch 85/150:\n",
      "Train Loss: 0.3015 | Train Acc: 88.88%\n",
      "Val Loss: 2.5107 | Val Acc: 52.01%\n",
      "Epoch 86/150:\n",
      "Train Loss: 0.3089 | Train Acc: 88.68%\n",
      "Val Loss: 2.4819 | Val Acc: 52.10%\n",
      "Epoch 87/150:\n",
      "Train Loss: 0.3057 | Train Acc: 88.68%\n",
      "Val Loss: 2.4804 | Val Acc: 51.75%\n",
      "Epoch 88/150:\n",
      "Train Loss: 0.3049 | Train Acc: 88.59%\n",
      "Val Loss: 2.5395 | Val Acc: 52.17%\n",
      "Epoch 89/150:\n",
      "Train Loss: 0.2996 | Train Acc: 88.94%\n",
      "Val Loss: 2.4893 | Val Acc: 51.93%\n",
      "Epoch 90/150:\n",
      "Train Loss: 0.2995 | Train Acc: 88.90%\n",
      "Val Loss: 2.5175 | Val Acc: 52.45%\n",
      "Epoch 91/150:\n",
      "Train Loss: 0.2997 | Train Acc: 88.78%\n",
      "Val Loss: 2.4462 | Val Acc: 52.15%\n",
      "Epoch 92/150:\n",
      "Train Loss: 0.2940 | Train Acc: 89.15%\n",
      "Val Loss: 2.4620 | Val Acc: 52.17%\n",
      "Epoch 93/150:\n",
      "Train Loss: 0.2919 | Train Acc: 89.11%\n",
      "Val Loss: 2.5198 | Val Acc: 52.44%\n",
      "Epoch 94/150:\n",
      "Train Loss: 0.2970 | Train Acc: 88.99%\n",
      "Val Loss: 2.5800 | Val Acc: 52.10%\n",
      "Epoch 95/150:\n",
      "Train Loss: 0.2945 | Train Acc: 89.15%\n",
      "Val Loss: 2.5145 | Val Acc: 52.29%\n",
      "Epoch 96/150:\n",
      "Train Loss: 0.2833 | Train Acc: 89.38%\n",
      "Val Loss: 2.4935 | Val Acc: 52.73%\n",
      "Epoch 97/150:\n",
      "Train Loss: 0.2892 | Train Acc: 89.21%\n",
      "Val Loss: 2.5121 | Val Acc: 52.29%\n",
      "Epoch 98/150:\n",
      "Train Loss: 0.2896 | Train Acc: 89.36%\n",
      "Val Loss: 2.5424 | Val Acc: 52.38%\n",
      "Epoch 99/150:\n",
      "Train Loss: 0.2882 | Train Acc: 89.12%\n",
      "Val Loss: 2.5474 | Val Acc: 52.19%\n",
      "Epoch 100/150:\n",
      "Train Loss: 0.2808 | Train Acc: 89.52%\n",
      "Val Loss: 2.5554 | Val Acc: 51.52%\n",
      "Epoch 101/150:\n",
      "Train Loss: 0.2826 | Train Acc: 89.55%\n",
      "Val Loss: 2.5741 | Val Acc: 51.72%\n",
      "Epoch 102/150:\n",
      "Train Loss: 0.2843 | Train Acc: 89.53%\n",
      "Val Loss: 2.6210 | Val Acc: 52.35%\n",
      "Epoch 103/150:\n",
      "Train Loss: 0.2795 | Train Acc: 89.57%\n",
      "Val Loss: 2.5740 | Val Acc: 52.11%\n",
      "Epoch 104/150:\n",
      "Train Loss: 0.2852 | Train Acc: 89.42%\n",
      "Val Loss: 2.5637 | Val Acc: 52.16%\n",
      "Epoch 105/150:\n",
      "Train Loss: 0.2772 | Train Acc: 89.58%\n",
      "Val Loss: 2.5922 | Val Acc: 51.99%\n",
      "Epoch 106/150:\n",
      "Train Loss: 0.2757 | Train Acc: 89.72%\n",
      "Val Loss: 2.5843 | Val Acc: 52.00%\n",
      "Epoch 107/150:\n",
      "Train Loss: 0.2772 | Train Acc: 89.74%\n",
      "Val Loss: 2.6212 | Val Acc: 52.53%\n",
      "Epoch 108/150:\n",
      "Train Loss: 0.2728 | Train Acc: 90.06%\n",
      "Val Loss: 2.6743 | Val Acc: 51.98%\n",
      "Epoch 109/150:\n",
      "Train Loss: 0.2746 | Train Acc: 89.67%\n",
      "Val Loss: 2.6263 | Val Acc: 52.52%\n",
      "Epoch 110/150:\n",
      "Train Loss: 0.2734 | Train Acc: 89.74%\n",
      "Val Loss: 2.6365 | Val Acc: 52.51%\n",
      "Epoch 111/150:\n",
      "Train Loss: 0.2739 | Train Acc: 89.66%\n",
      "Val Loss: 2.6289 | Val Acc: 52.12%\n",
      "Epoch 112/150:\n",
      "Train Loss: 0.2694 | Train Acc: 90.10%\n",
      "Val Loss: 2.6299 | Val Acc: 51.48%\n",
      "Epoch 113/150:\n",
      "Train Loss: 0.2675 | Train Acc: 89.94%\n",
      "Val Loss: 2.6728 | Val Acc: 51.97%\n",
      "Epoch 114/150:\n",
      "Train Loss: 0.2653 | Train Acc: 90.17%\n",
      "Val Loss: 2.5806 | Val Acc: 52.27%\n",
      "Epoch 115/150:\n",
      "Train Loss: 0.2630 | Train Acc: 90.16%\n",
      "Val Loss: 2.6644 | Val Acc: 52.37%\n",
      "Epoch 116/150:\n",
      "Train Loss: 0.2675 | Train Acc: 90.04%\n",
      "Val Loss: 2.6259 | Val Acc: 51.86%\n",
      "Epoch 117/150:\n",
      "Train Loss: 0.2613 | Train Acc: 90.28%\n",
      "Val Loss: 2.6743 | Val Acc: 52.25%\n",
      "Epoch 118/150:\n",
      "Train Loss: 0.2704 | Train Acc: 89.92%\n",
      "Val Loss: 2.6993 | Val Acc: 51.67%\n",
      "Epoch 119/150:\n",
      "Train Loss: 0.2623 | Train Acc: 90.44%\n",
      "Val Loss: 2.7624 | Val Acc: 51.87%\n",
      "Epoch 120/150:\n",
      "Train Loss: 0.2582 | Train Acc: 90.43%\n",
      "Val Loss: 2.7455 | Val Acc: 51.41%\n",
      "Epoch 121/150:\n",
      "Train Loss: 0.2531 | Train Acc: 90.67%\n",
      "Val Loss: 2.7676 | Val Acc: 51.98%\n",
      "Epoch 122/150:\n",
      "Train Loss: 0.2607 | Train Acc: 90.40%\n",
      "Val Loss: 2.8299 | Val Acc: 51.92%\n",
      "Epoch 123/150:\n",
      "Train Loss: 0.2574 | Train Acc: 90.51%\n",
      "Val Loss: 2.7442 | Val Acc: 52.11%\n",
      "Epoch 124/150:\n",
      "Train Loss: 0.2562 | Train Acc: 90.37%\n",
      "Val Loss: 2.7935 | Val Acc: 52.06%\n",
      "Epoch 125/150:\n",
      "Train Loss: 0.2601 | Train Acc: 90.30%\n",
      "Val Loss: 2.7857 | Val Acc: 51.79%\n",
      "Epoch 126/150:\n",
      "Train Loss: 0.2604 | Train Acc: 90.36%\n",
      "Val Loss: 2.7995 | Val Acc: 51.65%\n",
      "Epoch 127/150:\n",
      "Train Loss: 0.2504 | Train Acc: 90.44%\n",
      "Val Loss: 2.8721 | Val Acc: 51.73%\n",
      "Epoch 128/150:\n",
      "Train Loss: 0.2502 | Train Acc: 90.61%\n",
      "Val Loss: 2.8283 | Val Acc: 52.07%\n",
      "Epoch 129/150:\n",
      "Train Loss: 0.2516 | Train Acc: 90.54%\n",
      "Val Loss: 2.8051 | Val Acc: 52.02%\n",
      "Epoch 130/150:\n",
      "Train Loss: 0.2517 | Train Acc: 90.65%\n",
      "Val Loss: 2.8074 | Val Acc: 51.85%\n",
      "Epoch 131/150:\n",
      "Train Loss: 0.2524 | Train Acc: 90.60%\n",
      "Val Loss: 2.8345 | Val Acc: 51.74%\n",
      "Epoch 132/150:\n",
      "Train Loss: 0.2488 | Train Acc: 90.84%\n",
      "Val Loss: 2.7966 | Val Acc: 51.97%\n",
      "Epoch 133/150:\n",
      "Train Loss: 0.2548 | Train Acc: 90.53%\n",
      "Val Loss: 2.7730 | Val Acc: 52.17%\n",
      "Epoch 134/150:\n",
      "Train Loss: 0.2555 | Train Acc: 90.50%\n",
      "Val Loss: 2.8668 | Val Acc: 51.51%\n",
      "Epoch 135/150:\n",
      "Train Loss: 0.2490 | Train Acc: 90.53%\n",
      "Val Loss: 2.7896 | Val Acc: 51.81%\n",
      "Epoch 136/150:\n",
      "Train Loss: 0.2443 | Train Acc: 90.84%\n",
      "Val Loss: 2.8268 | Val Acc: 52.20%\n",
      "Epoch 137/150:\n",
      "Train Loss: 0.2404 | Train Acc: 90.96%\n",
      "Val Loss: 2.9306 | Val Acc: 51.73%\n",
      "Epoch 138/150:\n",
      "Train Loss: 0.2469 | Train Acc: 90.86%\n",
      "Val Loss: 2.8173 | Val Acc: 51.61%\n",
      "Epoch 139/150:\n",
      "Train Loss: 0.2447 | Train Acc: 90.74%\n",
      "Val Loss: 2.9064 | Val Acc: 51.78%\n",
      "Epoch 140/150:\n",
      "Train Loss: 0.2403 | Train Acc: 90.91%\n",
      "Val Loss: 2.9485 | Val Acc: 51.71%\n",
      "Epoch 141/150:\n",
      "Train Loss: 0.2416 | Train Acc: 91.16%\n",
      "Val Loss: 2.9594 | Val Acc: 51.76%\n",
      "Epoch 142/150:\n",
      "Train Loss: 0.2401 | Train Acc: 90.95%\n",
      "Val Loss: 2.8622 | Val Acc: 51.61%\n",
      "Epoch 143/150:\n",
      "Train Loss: 0.2405 | Train Acc: 91.13%\n",
      "Val Loss: 2.8215 | Val Acc: 51.85%\n",
      "Epoch 144/150:\n",
      "Train Loss: 0.2425 | Train Acc: 90.95%\n",
      "Val Loss: 2.8519 | Val Acc: 51.44%\n",
      "Epoch 145/150:\n",
      "Train Loss: 0.2403 | Train Acc: 90.93%\n",
      "Val Loss: 2.9758 | Val Acc: 51.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 672.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150:\n",
      "Train Loss: 0.2424 | Train Acc: 91.21%\n",
      "Val Loss: 2.8803 | Val Acc: 51.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 678.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150:\n",
      "Train Loss: 0.2334 | Train Acc: 91.28%\n",
      "Val Loss: 2.8810 | Val Acc: 51.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 681.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150:\n",
      "Train Loss: 0.2376 | Train Acc: 91.11%\n",
      "Val Loss: 2.9277 | Val Acc: 51.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 656.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150:\n",
      "Train Loss: 0.2332 | Train Acc: 91.24%\n",
      "Val Loss: 2.9452 | Val Acc: 51.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/150 - Training: 100%|██████████| 433/433 [00:00<00:00, 621.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150:\n",
      "Train Loss: 0.2352 | Train Acc: 91.39%\n",
      "Val Loss: 2.9345 | Val Acc: 51.73%\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando entrenamiento...\")\n",
    "model3 = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 53.84%\n"
     ]
    }
   ],
   "source": [
    "model3.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        features = batch['features'].to(device)\n",
    "        sequences = batch['sequence'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(sequences, features)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100.*test_correct/test_total\n",
    "print(f'\\nTest Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3.state_dict(), 'models/third-model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación modelo 3\n",
    "## Me lleva, sigue igual jajaja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
